#!/usr/bin/env python3
"""
PHASE 1: RESET & BASELINE
Clear ChromaDB cache corruption and establish 65-70% baseline

Usage:
    python scripts/phase1_reset_baseline.py
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass, asdict

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.rag import (
    create_embedding_model,
    create_vector_store,
    create_retriever,
    RetrievalStrategy,
)
from src.config import RAG_TOP_K, RAG_SIMILARITY_THRESHOLD
from src.observability import get_logger

logger = get_logger(__name__)


@dataclass
class BenchmarkResult:
    query: str
    framework: str
    expected_framework: str
    match: bool
    rank: int
    similarity: float


def wait_for_chromadb(max_retries=30, delay=2):
    """Wait for ChromaDB to be ready"""
    import chromadb

    logger.info("‚è≥ Waiting for ChromaDB to be ready...")
    for attempt in range(max_retries):
        try:
            client = chromadb.HttpClient(host="localhost", port=8000)
            client.heartbeat()
            logger.info(f"‚úÖ ChromaDB ready after {attempt * delay}s")
            return client
        except Exception as e:
            if attempt < max_retries - 1:
                logger.debug(f"  ChromaDB not ready, retrying in {delay}s...")
                time.sleep(delay)
            else:
                logger.error(f"‚ùå ChromaDB failed to start after {max_retries * delay}s")
                raise


def load_benchmark_queries() -> List[Dict]:
    """Load 27 benchmark queries from file"""
    benchmark_file = Path(__file__).parent.parent / "DOCS" / "rag" / "PHASE4_HYBRID_DISCOVERY.md"

    if not benchmark_file.exists():
        logger.warning(f"‚ö†Ô∏è Benchmark file not found: {benchmark_file}")
        # Fallback queries
        return [
            {"query": "Express server", "framework": "express"},
            {"query": "React component", "framework": "react"},
            {"query": "TypeScript interface", "framework": "typescript"},
            {"query": "Node.js middleware", "framework": "node"},
            {"query": "REST API endpoint", "framework": "express"},
            {"query": "React hooks", "framework": "react"},
            {"query": "async function", "framework": "javascript"},
            {"query": "database query", "framework": "database"},
            {"query": "error handling", "framework": "general"},
            {"query": "authentication", "framework": "general"},
        ]

    # Parse benchmark file to extract queries
    # For now, return fallback
    logger.info(f"üìÑ Loading queries from {benchmark_file}")
    return []


def load_examples_from_chromadb_backup() -> List[Dict]:
    """Load example data - from saved file or recreate"""
    examples_file = Path(__file__).parent.parent / "data" / "rag_examples.json"

    if examples_file.exists():
        logger.info(f"üì¶ Loading {examples_file.name}...")
        with open(examples_file) as f:
            data = json.load(f)
        logger.info(f"‚úÖ Loaded {len(data)} examples")
        return data

    logger.warning(f"‚ö†Ô∏è Examples file not found: {examples_file}")
    logger.info("   Will use existing data from vector store...")
    return []


def reset_chromadb():
    """1.1: Clear ChromaDB collection"""
    logger.info("\n" + "="*60)
    logger.info("1.1 CLEAR CHROMADB COLLECTION")
    logger.info("="*60)

    client = wait_for_chromadb()

    # Get all collections
    collections = client.list_collections()
    logger.info(f"Found {len(collections)} collections")

    for collection in collections:
        logger.info(f"  Deleting collection: {collection.name}")
        client.delete_collection(name=collection.name)

    logger.info("‚úÖ ChromaDB cleared")
    return client


def reingest_examples(vector_store):
    """1.2: Re-ingest all 146 examples"""
    logger.info("\n" + "="*60)
    logger.info("1.2 RE-INGEST ALL EXAMPLES")
    logger.info("="*60)

    examples = load_examples_from_chromadb_backup()

    if not examples:
        logger.warning("‚ö†Ô∏è No examples to ingest - skipping ingestion")
        logger.info("   You may need to load examples manually:")
        logger.info("   python scripts/ingest_rag_examples.py")
        return 0

    logger.info(f"üîÑ Ingesting {len(examples)} examples...")

    # Batch ingest
    batch_size = 32
    total = 0

    for i in range(0, len(examples), batch_size):
        batch = examples[i : i + batch_size]
        codes = [ex.get("code", "") for ex in batch]
        metadatas = [
            {
                k: v for k, v in ex.items()
                if k not in ["code", "id"] and v is not None
            }
            for ex in batch
        ]
        ids = [ex.get("id", f"ex_{i}_{j}") for j, ex in enumerate(batch)]

        try:
            vector_store.add_batch(codes=codes, metadatas=metadatas, ids=ids)
            total += len(batch)
            logger.info(f"  ‚úÖ Ingested {total}/{len(examples)}")
        except Exception as e:
            logger.error(f"‚ùå Error ingesting batch: {e}")
            continue

    logger.info(f"‚úÖ Re-ingestion complete: {total} examples")
    return total


def run_baseline_benchmark(retriever, queries: List[Dict]) -> Tuple[int, float, List[BenchmarkResult]]:
    """1.3: Run baseline benchmark with SIMILARITY strategy"""
    logger.info("\n" + "="*60)
    logger.info("1.3 BASELINE BENCHMARK (SIMILARITY STRATEGY)")
    logger.info("="*60)

    if not queries:
        logger.warning("‚ö†Ô∏è No queries to benchmark")
        return 0, 0.0, []

    logger.info(f"Running {len(queries)} benchmark queries...\n")

    results = []
    matches = 0
    similarities = []

    for query_dict in queries:
        query = query_dict.get("query", "")
        expected_framework = query_dict.get("framework", "unknown")

        if not query:
            continue

        try:
            # Retrieve top result
            retrieval_results = retriever.retrieve(query, top_k=1)

            if retrieval_results:
                top_result = retrieval_results[0]
                framework = top_result.metadata.get("framework", "unknown")
                match = framework == expected_framework

                result = BenchmarkResult(
                    query=query,
                    framework=framework,
                    expected_framework=expected_framework,
                    match=match,
                    rank=top_result.rank,
                    similarity=top_result.similarity,
                )
                results.append(result)

                if match:
                    matches += 1
                similarities.append(top_result.similarity)

                status = "‚úÖ" if match else "‚ùå"
                logger.info(
                    f"{status} [{query:30s}] ‚Üí {framework:15s} "
                    f"(sim: {top_result.similarity:.3f})"
                )
            else:
                logger.warning(f"‚ö†Ô∏è  No results for query: {query}")

        except Exception as e:
            logger.error(f"‚ùå Error querying '{query}': {e}")

    # Calculate metrics
    success_rate = (matches / len(results) * 100) if results else 0
    avg_similarity = sum(similarities) / len(similarities) if similarities else 0

    logger.info("\n" + "-"*60)
    logger.info(f"RESULTS: {matches}/{len(results)} matches ({success_rate:.1f}%)")
    logger.info(f"Average similarity: {avg_similarity:.3f}")
    logger.info("-"*60)

    return matches, success_rate, results


def main():
    """Execute PHASE 1: Reset & Baseline"""
    start_time = time.time()

    logger.info("üöÄ PHASE 1: RESET & BASELINE")
    logger.info(f"Started at {time.strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        # 1.1: Reset ChromaDB
        client = reset_chromadb()

        # Initialize RAG system
        logger.info("\nüì¶ Initializing RAG system...")
        embeddings = create_embedding_model()
        vector_store = create_vector_store(embeddings)
        retriever = create_retriever(
            vector_store=vector_store,
            strategy=RetrievalStrategy.SIMILARITY,
        )
        logger.info("‚úÖ RAG system initialized")

        # 1.2: Re-ingest examples
        ingested_count = reingest_examples(vector_store)

        if ingested_count == 0:
            logger.warning("\n‚ö†Ô∏è No examples ingested - skipping benchmark")
            logger.info("   Please manually load examples and run again")
            return 1

        # 1.3: Run baseline benchmark
        queries = load_benchmark_queries()
        matches, success_rate, results = run_baseline_benchmark(retriever, queries)

        # Save results
        output_file = Path(__file__).parent.parent / "DOCS" / "rag" / "phase1_baseline_results.json"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, "w") as f:
            json.dump({
                "phase": "PHASE 1: Reset & Baseline",
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "metrics": {
                    "total_queries": len(results),
                    "matches": matches,
                    "success_rate_percent": success_rate,
                    "average_similarity": sum(r.similarity for r in results) / len(results) if results else 0,
                },
                "results": [asdict(r) for r in results],
            }, f, indent=2)

        logger.info(f"\nüìä Results saved to: {output_file}")

        # Summary
        elapsed = time.time() - start_time
        logger.info("\n" + "="*60)
        logger.info("‚úÖ PHASE 1 COMPLETE")
        logger.info(f"   Success Rate: {success_rate:.1f}%")
        logger.info(f"   Examples Ingested: {ingested_count}")
        logger.info(f"   Time Elapsed: {elapsed:.1f}s")
        logger.info("="*60)

        return 0

    except Exception as e:
        logger.error(f"‚ùå PHASE 1 FAILED: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
