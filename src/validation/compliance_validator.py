"""
Compliance Validator - Semantic validation of generated code against spec

Compares spec requirements vs generated code to calculate compliance score.
Part of Task Group 4.1: Semantic Validation System.

Validates:
- Entity compliance: entities_found / entities_expected
- Endpoint compliance: endpoints_found / endpoints_expected
- Business logic compliance: validations_found / validations_expected
- Overall compliance: average of all categories

Threshold: FAIL if overall < 0.80 (80%)
"""

import logging
from typing import List, Dict, Any
from dataclasses import dataclass, field as dataclass_field

from src.parsing.spec_parser import SpecRequirements
from src.analysis.code_analyzer import CodeAnalyzer

logger = logging.getLogger(__name__)


@dataclass
class ComplianceReport:
    """
    Detailed compliance report

    Shows what was implemented vs what was expected,
    with compliance scores per category and overall.
    """

    overall_compliance: float  # 0.0-1.0

    # Entities
    entities_implemented: List[str] = dataclass_field(default_factory=list)
    entities_expected: List[str] = dataclass_field(default_factory=list)

    # Endpoints
    endpoints_implemented: List[str] = dataclass_field(default_factory=list)
    endpoints_expected: List[str] = dataclass_field(default_factory=list)

    # Business Logic
    validations_implemented: List[str] = dataclass_field(default_factory=list)
    validations_expected: List[str] = dataclass_field(default_factory=list)

    # Missing requirements
    missing_requirements: List[str] = dataclass_field(default_factory=list)

    # Per-category scores
    compliance_details: Dict[str, float] = dataclass_field(default_factory=dict)

    def __str__(self) -> str:
        """String representation of compliance report"""
        return f"""
Compliance Report
=================
Overall Compliance: {self.overall_compliance:.1%}

Entities: {self.compliance_details.get('entities', 0):.1%}
  Expected: {len(self.entities_expected)} - {', '.join(self.entities_expected)}
  Implemented: {len(self.entities_implemented)} - {', '.join(self.entities_implemented)}

Endpoints: {self.compliance_details.get('endpoints', 0):.1%}
  Expected: {len(self.endpoints_expected)}
  Implemented: {len(self.endpoints_implemented)}

Validations: {self.compliance_details.get('validations', 0):.1%}
  Expected: {len(self.validations_expected)}
  Implemented: {len(self.validations_implemented)}

Missing Requirements ({len(self.missing_requirements)}):
{chr(10).join('  - ' + req for req in self.missing_requirements[:10])}
"""


class ComplianceValidationError(Exception):
    """Raised when compliance is below threshold"""

    pass


class ComplianceValidator:
    """
    Validates generated code against specification requirements

    Calculates compliance score by comparing:
    1. Expected entities (from spec) vs Implemented entities (from code)
    2. Expected endpoints (from spec) vs Implemented endpoints (from code)
    3. Expected validations (from spec) vs Implemented validations (from code)

    Overall compliance = average of all category scores
    """

    def __init__(self):
        """Initialize compliance validator"""
        self.analyzer = CodeAnalyzer()
        logger.info("ComplianceValidator initialized")

    def validate(
        self, spec_requirements: SpecRequirements, generated_code: str
    ) -> ComplianceReport:
        """
        Validate generated code against specification

        Args:
            spec_requirements: Parsed specification with entities, endpoints, etc.
            generated_code: Python source code generated by CodeGenerationService

        Returns:
            ComplianceReport with detailed compliance analysis
        """
        logger.info("Starting compliance validation")

        # 1. Extract what was implemented
        entities_found = self.analyzer.extract_models(generated_code)
        endpoints_found = self.analyzer.extract_endpoints(generated_code)
        validations_found = self.analyzer.extract_validations(generated_code)

        # 2. Extract what was expected
        entities_expected = [e.name for e in spec_requirements.entities]
        endpoints_expected = [f"{ep.method} {ep.path}" for ep in spec_requirements.endpoints]

        # For validations, count business logic items + entity constraints
        validations_expected = []
        for bl in spec_requirements.business_logic:
            if bl.type == "validation":
                validations_expected.append(bl.description)

        # Add entity field constraints as expected validations
        for entity in spec_requirements.entities:
            for field in entity.fields:
                if field.constraints:
                    validations_expected.extend(field.constraints)

        # If no explicit validations, use a minimum count based on entities
        if not validations_expected and entities_expected:
            # Expect at least 2 validations per entity (heuristic)
            validations_expected = [f"validation_{i}" for i in range(len(entities_expected) * 2)]

        # 3. Calculate compliance per category
        entity_compliance = self._calculate_compliance(entities_found, entities_expected)
        endpoint_compliance = self._calculate_endpoint_compliance_fuzzy(endpoints_found, endpoints_expected)
        validation_compliance = self._calculate_validation_compliance(
            validations_found, validations_expected
        )

        # 4. Calculate overall compliance (weighted average)
        # Entities and endpoints are more important than validations
        overall_compliance = (
            entity_compliance * 0.40 + endpoint_compliance * 0.40 + validation_compliance * 0.20
        )

        # 5. Identify missing requirements
        missing = self._identify_missing_requirements(
            entities_expected,
            entities_found,
            endpoints_expected,
            endpoints_found,
            spec_requirements,
        )

        # 6. Build detailed report
        report = ComplianceReport(
            overall_compliance=overall_compliance,
            entities_implemented=entities_found,
            entities_expected=entities_expected,
            endpoints_implemented=endpoints_found,
            endpoints_expected=endpoints_expected,
            validations_implemented=validations_found,
            validations_expected=validations_expected,
            missing_requirements=missing,
            compliance_details={
                "entities": entity_compliance,
                "endpoints": endpoint_compliance,
                "validations": validation_compliance,
            },
        )

        logger.info(
            f"Compliance validation complete: {overall_compliance:.1%} "
            f"(entities: {entity_compliance:.1%}, "
            f"endpoints: {endpoint_compliance:.1%}, "
            f"validations: {validation_compliance:.1%})"
        )

        return report

    def validate_from_app(
        self, spec_requirements: SpecRequirements, output_path
    ) -> ComplianceReport:
        """
        Validate generated code using OpenAPI schema from running app.

        CRITICAL FIX for 0% compliance bug: Instead of parsing main.py string,
        this dynamically imports the generated FastAPI app and reads its OpenAPI schema.

        This finds ALL entities and endpoints across modular architecture:
        - Entities from OpenAPI schemas (src/models/schemas.py)
        - Endpoints from OpenAPI paths (src/api/routes/*.py)

        Args:
            spec_requirements: Parsed specification with entities, endpoints, etc.
            output_path: Path to generated app directory (e.g., tests/e2e/generated_apps/app_123/)

        Returns:
            ComplianceReport with REAL compliance analysis
        """
        import sys
        import importlib.util
        from pathlib import Path

        # Ensure output_path is Path object and convert to absolute path
        if not isinstance(output_path, Path):
            output_path = Path(output_path).resolve()
        else:
            output_path = output_path.resolve()

        logger.info(f"Validating app at {output_path} using OpenAPI schema")

        # Add output_path to sys.path for imports
        output_path_str = str(output_path)
        if output_path_str not in sys.path:
            sys.path.insert(0, output_path_str)

        try:
            # Import the generated FastAPI app
            main_py_path = output_path / "src" / "main.py"

            if not main_py_path.exists():
                logger.error(f"main.py not found at {main_py_path}")
                # Fallback to old validation method
                logger.warning("Falling back to string-based validation (will show low compliance)")
                main_code = ""
                if (output_path / "src" / "main.py").exists():
                    main_code = (output_path / "src" / "main.py").read_text()
                return self.validate(spec_requirements, main_code)

            # Configure temporary database for validation (avoid global DATABASE_URL issues)
            # Use asyncpg driver to avoid psycopg2 async errors
            import os
            original_database_url = os.environ.get('DATABASE_URL')
            # Use dummy async PostgreSQL URL (won't actually connect during OpenAPI extraction)
            os.environ['DATABASE_URL'] = 'postgresql+asyncpg://validation:validation@localhost/validation_temp'

            try:
                # Load main.py as module with proper package context
                # Add app root to sys.path temporarily so absolute imports work
                import sys
                app_root = str(output_path)
                sys.path.insert(0, app_root)

                try:
                    # Import using spec but set __package__ correctly
                    spec = importlib.util.spec_from_file_location("src.main", main_py_path, submodule_search_locations=[app_root])
                    main_module = importlib.util.module_from_spec(spec)
                    # Set package context so absolute imports like "from src.core.logging" work
                    main_module.__package__ = "src"
                    sys.modules['src.main'] = main_module
                    spec.loader.exec_module(main_module)
                finally:
                    # Remove app root from sys.path
                    if app_root in sys.path:
                        sys.path.remove(app_root)
            finally:
                # Restore original DATABASE_URL
                if original_database_url is not None:
                    os.environ['DATABASE_URL'] = original_database_url
                else:
                    os.environ.pop('DATABASE_URL', None)

            # Get FastAPI app instance
            app = main_module.app

            logger.info("Successfully imported FastAPI app")

            # Extract OpenAPI schema
            openapi_schema = app.openapi()

            # 1. Extract entities from OpenAPI schemas
            entities_found = []
            schemas = openapi_schema.get("components", {}).get("schemas", {})

            for schema_name in schemas.keys():
                # Filter domain entities (exclude Create, Update, Response, List suffixes)
                if not any(schema_name.endswith(suffix) for suffix in ['Create', 'Update', 'Response', 'List']):
                    entities_found.append(schema_name)

            # Also check for entities with "Entity" suffix (SQLAlchemy models)
            # These might be referenced but not directly in schemas
            entities_expected_lower = {e.lower() for e in [ent.name for ent in spec_requirements.entities]}
            for schema_name in schemas.keys():
                # Check if this matches an expected entity (case-insensitive)
                base_name = schema_name.replace('Entity', '').replace('Create', '').replace('Update', '').replace('Response', '').replace('List', '')
                if base_name.lower() in entities_expected_lower and base_name not in entities_found:
                    entities_found.append(base_name)

            logger.info(f"Extracted {len(entities_found)} entities from OpenAPI schemas: {entities_found}")

            # 2. Extract endpoints from OpenAPI paths
            endpoints_found = []
            paths = openapi_schema.get("paths", {})

            for path, methods in paths.items():
                for method in methods.keys():
                    # Only include actual HTTP methods (not 'parameters', 'summary', etc.)
                    if method.upper() in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE', 'HEAD', 'OPTIONS']:
                        endpoints_found.append(f"{method.upper()} {path}")

            logger.info(f"Extracted {len(endpoints_found)} endpoints from OpenAPI paths")

            # 3. Extract validations (heuristic from schemas)
            validations_found = []
            for schema_name, schema_def in schemas.items():
                properties = schema_def.get("properties", {})
                for prop_name, prop_def in properties.items():
                    # Check for validation constraints
                    if "minimum" in prop_def or "maximum" in prop_def:
                        validations_found.append(f"range validation on {prop_name}")
                    if "minLength" in prop_def or "maxLength" in prop_def:
                        validations_found.append(f"length validation on {prop_name}")
                    if "pattern" in prop_def:
                        validations_found.append(f"pattern validation on {prop_name}")
                    if prop_def.get("format") == "email":
                        validations_found.append(f"email validation on {prop_name}")

            logger.info(f"Extracted {len(validations_found)} validations from schemas")

            # 4. Extract what was expected from spec
            entities_expected = [e.name for e in spec_requirements.entities]
            endpoints_expected = [f"{ep.method} {ep.path}" for ep in spec_requirements.endpoints]

            # For validations, count business logic items + entity constraints
            validations_expected = []
            for bl in spec_requirements.business_logic:
                if bl.type == "validation":
                    validations_expected.append(bl.description)

            # Add entity field constraints as expected validations
            for entity in spec_requirements.entities:
                for field in entity.fields:
                    if field.constraints:
                        validations_expected.extend(field.constraints)

            # If no explicit validations, use a minimum count based on entities
            if not validations_expected and entities_expected:
                # Expect at least 2 validations per entity (heuristic)
                validations_expected = [f"validation_{i}" for i in range(len(entities_expected) * 2)]

            # 5. Calculate compliance per category
            entity_compliance = self._calculate_compliance(entities_found, entities_expected)
            endpoint_compliance = self._calculate_endpoint_compliance_fuzzy(endpoints_found, endpoints_expected)
            validation_compliance = self._calculate_validation_compliance(
                validations_found, validations_expected
            )

            # 6. Calculate overall compliance (weighted average)
            # Entities and endpoints are more important than validations
            overall_compliance = (
                entity_compliance * 0.40 + endpoint_compliance * 0.40 + validation_compliance * 0.20
            )

            # 7. Identify missing requirements
            missing = self._identify_missing_requirements(
                entities_expected,
                entities_found,
                endpoints_expected,
                endpoints_found,
                spec_requirements,
            )

            # 8. Build detailed report
            report = ComplianceReport(
                overall_compliance=overall_compliance,
                entities_implemented=entities_found,
                entities_expected=entities_expected,
                endpoints_implemented=endpoints_found,
                endpoints_expected=endpoints_expected,
                validations_implemented=validations_found,
                validations_expected=validations_expected,
                missing_requirements=missing,
                compliance_details={
                    "entities": entity_compliance,
                    "endpoints": endpoint_compliance,
                    "validations": validation_compliance,
                },
            )

            logger.info(
                f"OpenAPI-based compliance validation complete: {overall_compliance:.1%} "
                f"(entities: {entity_compliance:.1%}, "
                f"endpoints: {endpoint_compliance:.1%}, "
                f"validations: {validation_compliance:.1%})"
            )

            return report

        except Exception as e:
            logger.error(f"Error importing app for OpenAPI validation: {e}")
            import traceback
            traceback.print_exc()

            # Fallback to old validation method
            logger.warning("Falling back to string-based validation (will show low compliance)")
            main_code = ""
            if (output_path / "src" / "main.py").exists():
                main_code = (output_path / "src" / "main.py").read_text()
            return self.validate(spec_requirements, main_code)

        finally:
            # Clean up sys.path
            if output_path_str in sys.path:
                sys.path.remove(output_path_str)

    def validate_or_raise(
        self, spec_requirements: SpecRequirements, generated_code: str, threshold: float = 0.80
    ) -> ComplianceReport:
        """
        Validate and raise exception if compliance below threshold

        Args:
            spec_requirements: Parsed specification
            generated_code: Generated Python code
            threshold: Minimum compliance score (default 0.80 = 80%)

        Returns:
            ComplianceReport if compliance >= threshold

        Raises:
            ComplianceValidationError: If compliance < threshold
        """
        report = self.validate(spec_requirements, generated_code)

        if report.overall_compliance < threshold:
            error_msg = (
                f"Compliance validation FAILED: {report.overall_compliance:.1%} "
                f"(threshold: {threshold:.1%})\n\n"
                f"{report}"
            )
            logger.error(error_msg)
            raise ComplianceValidationError(error_msg)

        logger.info(f"Compliance validation PASSED: {report.overall_compliance:.1%}")
        return report

    def _calculate_compliance(self, found: List[str], expected: List[str]) -> float:
        """
        Calculate compliance score for a category

        Uses set intersection to handle case variations and extra items.

        Args:
            found: Items found in generated code
            expected: Items expected from spec

        Returns:
            Compliance score 0.0-1.0
        """
        if not expected:
            return 1.0  # No requirements = 100% compliance

        if not found:
            return 0.0  # Nothing implemented = 0% compliance

        # Normalize for comparison (case-insensitive, strip whitespace)
        found_normalized = {item.strip().lower() for item in found}
        expected_normalized = {item.strip().lower() for item in expected}

        # Count how many expected items were found
        matches = found_normalized & expected_normalized
        compliance = len(matches) / len(expected_normalized)

        return min(compliance, 1.0)  # Cap at 100%

    def _calculate_endpoint_compliance_fuzzy(self, found: List[str], expected: List[str]) -> float:
        """
        Calculate endpoint compliance with fuzzy matching

        Fuzzy matching handles:
        1. Path parameter variations: /carts/{id} â‰ˆ /carts/{customer_id}
        2. Functionally equivalent HTTP methods: POST vs DELETE for "clear/empty"
        3. Route variations: /carts/clear â‰ˆ /carts/{id} for clear operations

        Args:
            found: Endpoints found in generated code (format: "GET /products")
            expected: Endpoints expected from spec

        Returns:
            Compliance score 0.0-1.0
        """
        if not expected:
            return 1.0

        if not found:
            return 0.0

        # Parse endpoints into (method, path) tuples
        def parse_endpoint(endpoint_str: str):
            parts = endpoint_str.strip().split(maxsplit=1)
            if len(parts) == 2:
                return parts[0].upper(), parts[1]
            return None, None

        expected_parsed = []
        for exp in expected:
            method, path = parse_endpoint(exp)
            if method and path:
                expected_parsed.append((method, path))

        found_parsed = []
        for fnd in found:
            method, path = parse_endpoint(fnd)
            if method and path:
                found_parsed.append((method, path))

        # Count fuzzy matches
        matches = 0
        for exp_method, exp_path in expected_parsed:
            if self._is_fuzzy_endpoint_match(exp_method, exp_path, found_parsed):
                matches += 1

        compliance = matches / len(expected_parsed) if expected_parsed else 0.0

        logger.debug(
            f"Endpoint fuzzy matching: {matches}/{len(expected_parsed)} matches "
            f"({compliance:.1%})"
        )

        return min(compliance, 1.0)

    def _is_fuzzy_endpoint_match(
        self,
        expected_method: str,
        expected_path: str,
        found_endpoints: List[tuple]
    ) -> bool:
        """
        Check if expected endpoint matches any found endpoint using fuzzy rules

        Args:
            expected_method: Expected HTTP method (GET, POST, etc.)
            expected_path: Expected path (/carts/{customer_id})
            found_endpoints: List of (method, path) tuples from generated code

        Returns:
            True if a fuzzy match is found
        """
        # Normalize paths: replace {any_param} with {id} for comparison
        def normalize_path(path: str) -> str:
            import re
            # Replace all {param_name} with {*} for fuzzy matching
            return re.sub(r'\{[^}]+\}', '{*}', path.lower().strip())

        expected_path_norm = normalize_path(expected_path)

        for found_method, found_path in found_endpoints:
            found_path_norm = normalize_path(found_path)

            # 1. Exact match (method + normalized path)
            if expected_method == found_method and expected_path_norm == found_path_norm:
                return True

            # 2. Functionally equivalent methods for specific operations
            if self._are_methods_functionally_equivalent(
                expected_method, found_method, expected_path, found_path
            ):
                # Check if paths are semantically similar
                if self._are_paths_similar(expected_path, found_path):
                    return True

        return False

    def _are_methods_functionally_equivalent(
        self,
        method1: str,
        method2: str,
        path1: str,
        path2: str
    ) -> bool:
        """
        Check if two HTTP methods are functionally equivalent for the operation

        Examples:
        - DELETE /carts/{id} â‰ˆ POST /carts/clear (both clear/empty cart)
        - PUT /orders/{id}/cancel â‰ˆ POST /orders/cancel (both cancel order)

        Args:
            method1, method2: HTTP methods to compare
            path1, path2: Paths to provide context

        Returns:
            True if methods are functionally equivalent
        """
        # Normalize methods
        m1, m2 = method1.upper(), method2.upper()

        # If methods are the same, they're equivalent
        if m1 == m2:
            return True

        # Check for clear/empty/delete operations
        if "clear" in path1.lower() or "clear" in path2.lower():
            # POST /carts/clear â‰ˆ DELETE /carts/{id}
            if {m1, m2} == {"POST", "DELETE"}:
                return True

        # Check for cancel operations
        if "cancel" in path1.lower() or "cancel" in path2.lower():
            # POST /orders/cancel â‰ˆ PUT /orders/{id}/cancel
            if {m1, m2} <= {"POST", "PUT", "PATCH"}:
                return True

        return False

    def _are_paths_similar(self, path1: str, path2: str) -> bool:
        """
        Check if two paths are semantically similar

        Examples:
        - /carts/{id} â‰ˆ /carts/{customer_id}
        - /carts/clear â‰ˆ /carts/{id} (for delete/clear operations)
        - /orders/{id}/cancel â‰ˆ /orders/cancel

        Args:
            path1, path2: Paths to compare

        Returns:
            True if paths are similar enough
        """
        import re

        # Normalize: lowercase, strip slashes
        p1 = path1.lower().strip().strip('/')
        p2 = path2.lower().strip().strip('/')

        # Exact match
        if p1 == p2:
            return True

        # Replace all {params} with placeholder for comparison
        p1_norm = re.sub(r'\{[^}]+\}', 'PARAM', p1)
        p2_norm = re.sub(r'\{[^}]+\}', 'PARAM', p2)

        # Match if normalized paths are the same
        if p1_norm == p2_norm:
            return True

        # Check for clear/cancel variations
        # /carts/{id} â‰ˆ /carts/clear
        p1_parts = p1_norm.split('/')
        p2_parts = p2_norm.split('/')

        if len(p1_parts) == len(p2_parts):
            # Same base path and either both have PARAM or one has clear/cancel
            if p1_parts[:-1] == p2_parts[:-1]:
                last1, last2 = p1_parts[-1], p2_parts[-1]
                if 'PARAM' in {last1, last2} and any(
                    x in {last1, last2} for x in ['clear', 'cancel', 'checkout']
                ):
                    return True

        return False

    def _calculate_validation_compliance(self, found: List[str], expected: List[str]) -> float:
        """
        Calculate validation compliance with more lenient matching

        Validations can be expressed in multiple ways, so we use
        keyword matching instead of exact matching.

        Args:
            found: Validation signatures found in code
            expected: Validation requirements from spec

        Returns:
            Compliance score 0.0-1.0
        """
        if not expected:
            return 1.0

        if not found:
            return 0.0

        # For validations, use more flexible matching
        # Count validation types present
        validation_types = {
            "price": any("price" in v.lower() for v in found),
            "stock": any("stock" in v.lower() for v in found),
            "email": any("email" in v.lower() for v in found),
            "quantity": any("quantity" in v.lower() for v in found),
            "field": any("field" in v.lower() for v in found),
            "validation": any("validation" in v.lower() for v in found),
        }

        # Count how many validation types are expected
        expected_types = {
            "price": any("price" in v.lower() for v in expected),
            "stock": any("stock" in v.lower() for v in expected),
            "email": any("email" in v.lower() for v in expected),
            "quantity": any("quantity" in v.lower() for v in expected),
            "field": any("gt" in v.lower() or "ge" in v.lower() for v in expected),
            "validation": True,  # Always expect some validation
        }

        # Calculate match ratio
        matches = sum(
            1
            for key in validation_types
            if validation_types[key] and expected_types.get(key, False)
        )
        total_expected = sum(1 for val in expected_types.values() if val)

        if total_expected == 0:
            return 1.0

        compliance = matches / total_expected

        # Minimum score based on presence of any validations
        if found:
            compliance = max(compliance, 0.3)  # At least 30% if any validations exist

        return min(compliance, 1.0)

    def _identify_missing_requirements(
        self,
        entities_expected: List[str],
        entities_found: List[str],
        endpoints_expected: List[str],
        endpoints_found: List[str],
        spec: SpecRequirements,
    ) -> List[str]:
        """
        Identify specific missing requirements

        Args:
            entities_expected: Expected entity names
            entities_found: Found entity names
            endpoints_expected: Expected endpoints
            endpoints_found: Found endpoints
            spec: Full spec requirements

        Returns:
            List of missing requirement descriptions
        """
        missing = []

        # Missing entities
        entities_found_normalized = {e.lower() for e in entities_found}
        for entity in entities_expected:
            if entity.lower() not in entities_found_normalized:
                missing.append(f"Entity: {entity}")

        # Missing endpoints (sample first 5 to avoid spam)
        endpoints_found_normalized = {e.lower() for e in endpoints_found}
        missing_endpoints = []
        for endpoint in endpoints_expected:
            if endpoint.lower() not in endpoints_found_normalized:
                missing_endpoints.append(f"Endpoint: {endpoint}")

        # Add sample of missing endpoints
        missing.extend(missing_endpoints[:5])
        if len(missing_endpoints) > 5:
            missing.append(f"... and {len(missing_endpoints) - 5} more endpoints")

        # Missing functional requirements (sample)
        for req in spec.requirements[:5]:
            if req.type == "functional":
                # Check if requirement keywords are in code (heuristic)
                # This is a simplified check
                missing.append(f"Requirement {req.id}: {req.description[:60]}...")

        return missing

    def _format_entity_report(
        self,
        report: ComplianceReport
    ) -> str:
        """
        Enhanced entity report with categorization

        Separates:
        - Domain entities (Product, Customer, etc.)
        - Request/Response schemas (ProductCreate, etc.)
        - Enums (Status enums)

        Args:
            report: ComplianceReport with entities data

        Returns:
            Formatted string with categorized entities

        Part of Task Group 2: Presentation Enhancement (M4)
        """
        # Categorize entities
        domain_entities = []
        schemas = []
        enums = []

        for entity in report.entities_implemented:
            if entity in report.entities_expected:
                domain_entities.append(entity)
            elif entity.endswith(('Create', 'Update', 'Request', 'Response')):
                schemas.append(entity)
            elif entity.endswith('Status'):
                enums.append(entity)
            else:
                # Unknown category - treat as domain entity
                domain_entities.append(entity)

        # Format output
        lines = []
        lines.append(f"\nðŸ“¦ Entities ({len(report.entities_expected)} required, {len(domain_entities)} present):")
        lines.append(f"   âœ… {', '.join(domain_entities)}")

        if schemas or enums:
            lines.append(f"\n   ðŸ“ Additional models (best practices):")
            if schemas:
                lines.append(f"   - Request/Response schemas: {len(schemas)}")
            if enums:
                lines.append(f"   - Enums: {len(enums)}")

        return "\n".join(lines)

    def _format_endpoint_report(
        self,
        report: ComplianceReport
    ) -> str:
        """
        Enhanced endpoint report with categorization

        Separates:
        - Required endpoints (from spec)
        - Additional endpoints (best practices like / and /health)

        Args:
            report: ComplianceReport with endpoints data

        Returns:
            Formatted string with categorized endpoints

        Part of Task Group 2: Presentation Enhancement (M4)
        """
        # Categorize endpoints
        required_endpoints = []
        additional_endpoints = []

        for endpoint in report.endpoints_implemented:
            if endpoint in report.endpoints_expected:
                required_endpoints.append(endpoint)
            else:
                # Additional endpoints (best practices)
                additional_endpoints.append(endpoint)

        # Format output
        lines = []
        lines.append(f"\nðŸŒ Endpoints ({len(report.endpoints_expected)} required, {len(required_endpoints)} present):")
        
        if required_endpoints:
            # Show sample of required endpoints (first 5)
            sample = required_endpoints[:5]
            lines.append(f"   âœ… {', '.join(sample)}")
            if len(required_endpoints) > 5:
                lines.append(f"   ... and {len(required_endpoints) - 5} more")
        else:
            lines.append(f"   âŒ No required endpoints found")

        if additional_endpoints:
            lines.append(f"\n   ðŸ“ Additional endpoints (best practices):")
            for endpoint in additional_endpoints:
                lines.append(f"   - {endpoint}")

        return "\n".join(lines)

    def generate_detailed_report(
        self, spec_requirements: SpecRequirements, generated_code: str
    ) -> Dict[str, Any]:
        """
        Generate comprehensive compliance report with all details

        Args:
            spec_requirements: Parsed specification
            generated_code: Generated code

        Returns:
            Dict with full compliance analysis
        """
        report = self.validate(spec_requirements, generated_code)
        stats = self.analyzer.get_code_statistics(generated_code)

        detailed_report = {
            "compliance": {
                "overall": report.overall_compliance,
                "entities": report.compliance_details["entities"],
                "endpoints": report.compliance_details["endpoints"],
                "validations": report.compliance_details["validations"],
            },
            "entities": {
                "expected": report.entities_expected,
                "implemented": report.entities_implemented,
                "missing": [
                    e for e in report.entities_expected if e not in report.entities_implemented
                ],
            },
            "endpoints": {
                "expected_count": len(report.endpoints_expected),
                "implemented_count": len(report.endpoints_implemented),
                "sample_expected": report.endpoints_expected[:5],
                "sample_implemented": report.endpoints_implemented[:5],
            },
            "validations": {
                "expected_count": len(report.validations_expected),
                "implemented_count": len(report.validations_implemented),
                "types_found": report.validations_implemented,
            },
            "code_statistics": stats,
            "missing_requirements": report.missing_requirements,
            "passed": report.overall_compliance >= 0.80,
        }

        return detailed_report
