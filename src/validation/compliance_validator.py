"""
Compliance Validator - Semantic validation of generated code against spec

Compares spec requirements vs generated code to calculate compliance score.
Part of Task Group 4.1: Semantic Validation System.

Validates:
- Entity compliance: entities_found / entities_expected
- Endpoint compliance: endpoints_found / endpoints_expected
- Business logic compliance: validations_found / validations_expected
- Overall compliance: average of all categories

Threshold: FAIL if overall < 0.80 (80%)
"""

import logging
from typing import List, Dict, Any
from dataclasses import dataclass, field as dataclass_field

from src.parsing.spec_parser import SpecRequirements
from src.analysis.code_analyzer import CodeAnalyzer

logger = logging.getLogger(__name__)


@dataclass
class ComplianceReport:
    """
    Detailed compliance report

    Shows what was implemented vs what was expected,
    with compliance scores per category and overall.
    """

    overall_compliance: float  # 0.0-1.0

    # Entities
    entities_implemented: List[str] = dataclass_field(default_factory=list)
    entities_expected: List[str] = dataclass_field(default_factory=list)

    # Endpoints
    endpoints_implemented: List[str] = dataclass_field(default_factory=list)
    endpoints_expected: List[str] = dataclass_field(default_factory=list)

    # Business Logic
    validations_implemented: List[str] = dataclass_field(default_factory=list)
    validations_expected: List[str] = dataclass_field(default_factory=list)

    # Missing requirements
    missing_requirements: List[str] = dataclass_field(default_factory=list)

    # Per-category scores
    compliance_details: Dict[str, float] = dataclass_field(default_factory=dict)

    def __str__(self) -> str:
        """String representation of compliance report"""
        return f"""
Compliance Report
=================
Overall Compliance: {self.overall_compliance:.1%}

Entities: {self.compliance_details.get('entities', 0):.1%}
  Expected: {len(self.entities_expected)} - {', '.join(self.entities_expected)}
  Implemented: {len(self.entities_implemented)} - {', '.join(self.entities_implemented)}

Endpoints: {self.compliance_details.get('endpoints', 0):.1%}
  Expected: {len(self.endpoints_expected)}
  Implemented: {len(self.endpoints_implemented)}

Validations: {self.compliance_details.get('validations', 0):.1%}
  Expected: {len(self.validations_expected)}
  Implemented: {len(self.validations_implemented)}

Missing Requirements ({len(self.missing_requirements)}):
{chr(10).join('  - ' + req for req in self.missing_requirements[:10])}
"""


class ComplianceValidationError(Exception):
    """Raised when compliance is below threshold"""

    pass


class ComplianceValidator:
    """
    Validates generated code against specification requirements

    Calculates compliance score by comparing:
    1. Expected entities (from spec) vs Implemented entities (from code)
    2. Expected endpoints (from spec) vs Implemented endpoints (from code)
    3. Expected validations (from spec) vs Implemented validations (from code)

    Overall compliance = average of all category scores
    """

    def __init__(self):
        """Initialize compliance validator"""
        self.analyzer = CodeAnalyzer()
        logger.info("ComplianceValidator initialized")

    def validate(
        self, spec_requirements: SpecRequirements, generated_code: str
    ) -> ComplianceReport:
        """
        Validate generated code against specification

        Args:
            spec_requirements: Parsed specification with entities, endpoints, etc.
            generated_code: Python source code generated by CodeGenerationService

        Returns:
            ComplianceReport with detailed compliance analysis
        """
        logger.info("Starting compliance validation")

        # 1. Extract what was implemented
        entities_found = self.analyzer.extract_models(generated_code)
        endpoints_found = self.analyzer.extract_endpoints(generated_code)
        validations_found = self.analyzer.extract_validations(generated_code)

        # 2. Extract what was expected
        entities_expected = [e.name for e in spec_requirements.entities]
        endpoints_expected = [f"{ep.method} {ep.path}" for ep in spec_requirements.endpoints]

        # For validations, use ground truth if available, otherwise fallback to old logic
        validations_expected = []

        if spec_requirements.validation_ground_truth and 'validations' in spec_requirements.validation_ground_truth:
            # Use ground truth validations
            for val_id, val_data in spec_requirements.validation_ground_truth['validations'].items():
                entity = val_data.get('entity', '')
                field = val_data.get('field', '')
                constraint = val_data.get('constraint', '')
                # Format: "Entity.field: constraint"
                validations_expected.append(f"{entity}.{field}: {constraint}")
            logger.info(f"Using validation ground truth: {len(validations_expected)} validations expected")
        else:
            # Fallback to old logic
            for bl in spec_requirements.business_logic:
                if bl.type == "validation":
                    validations_expected.append(bl.description)

            # Add entity field constraints as expected validations
            for entity in spec_requirements.entities:
                for field in entity.fields:
                    if field.constraints:
                        validations_expected.extend(field.constraints)

            # If no explicit validations, use a minimum count based on entities
            if not validations_expected and entities_expected:
                # Expect at least 2 validations per entity (heuristic)
                validations_expected = [f"validation_{i}" for i in range(len(entities_expected) * 2)]

        # 3. Calculate compliance per category
        entity_compliance = self._calculate_compliance(entities_found, entities_expected)
        endpoint_compliance = self._calculate_endpoint_compliance_fuzzy(endpoints_found, endpoints_expected)

        # Use exact matching if ground truth is available, otherwise use flexible matching
        use_exact_matching = bool(spec_requirements.validation_ground_truth and 'validations' in spec_requirements.validation_ground_truth)
        validation_compliance, validations_matched = self._calculate_validation_compliance(
            validations_found, validations_expected, use_exact_matching=use_exact_matching
        )

        # 4. Calculate overall compliance (weighted average)
        # Entities and endpoints are more important than validations
        overall_compliance = (
            entity_compliance * 0.40 + endpoint_compliance * 0.40 + validation_compliance * 0.20
        )

        # 5. Identify missing requirements
        missing = self._identify_missing_requirements(
            entities_expected,
            entities_found,
            endpoints_expected,
            endpoints_found,
            spec_requirements,
        )

        # 6. Build detailed report
        # Use matched validations (not all found) when ground truth exists for accurate metrics
        report = ComplianceReport(
            overall_compliance=overall_compliance,
            entities_implemented=entities_found,
            entities_expected=entities_expected,
            endpoints_implemented=endpoints_found,
            endpoints_expected=endpoints_expected,
            validations_implemented=validations_matched,  # Only matched validations, not all found
            validations_expected=validations_expected,
            missing_requirements=missing,
            compliance_details={
                "entities": entity_compliance,
                "endpoints": endpoint_compliance,
                "validations": validation_compliance,
            },
        )

        logger.info(
            f"Compliance validation complete: {overall_compliance:.1%} "
            f"(entities: {entity_compliance:.1%}, "
            f"endpoints: {endpoint_compliance:.1%}, "
            f"validations: {validation_compliance:.1%})"
        )

        return report

    def validate_from_app(
        self, spec_requirements: SpecRequirements, output_path
    ) -> ComplianceReport:
        """
        Validate generated code using OpenAPI schema from running app.

        CRITICAL FIX for 0% compliance bug: Instead of parsing main.py string,
        this dynamically imports the generated FastAPI app and reads its OpenAPI schema.

        This finds ALL entities and endpoints across modular architecture:
        - Entities from OpenAPI schemas (src/models/schemas.py)
        - Endpoints from OpenAPI paths (src/api/routes/*.py)

        Args:
            spec_requirements: Parsed specification with entities, endpoints, etc.
            output_path: Path to generated app directory (e.g., tests/e2e/generated_apps/app_123/)

        Returns:
            ComplianceReport with REAL compliance analysis
        """
        import sys
        import importlib.util
        from pathlib import Path

        # Ensure output_path is Path object and convert to absolute path
        if not isinstance(output_path, Path):
            output_path = Path(output_path).resolve()
        else:
            output_path = output_path.resolve()

        logger.info(f"Validating app at {output_path} using OpenAPI schema")

        # Add output_path to sys.path for imports
        output_path_str = str(output_path)
        if output_path_str not in sys.path:
            sys.path.insert(0, output_path_str)

        try:
            # Import the generated FastAPI app
            # Try src/main.py first (standard DevMatrix structure)
            main_py_path = output_path / "src" / "main.py"
            is_root_main = False  # Track if main.py is in root vs src/

            # Fallback: try main.py in root if src/main.py doesn't exist
            if not main_py_path.exists():
                root_main_py = output_path / "main.py"
                if root_main_py.exists():
                    logger.info(f"Found main.py in root (not in src/)")
                    main_py_path = root_main_py
                    is_root_main = True
                else:
                    logger.error(f"main.py not found at {output_path / 'src' / 'main.py'} or {root_main_py}")
                    # Fallback to old validation method
                    logger.warning("Falling back to string-based validation (will show low compliance)")
                    main_code = ""
                    if root_main_py.exists():
                        main_code = root_main_py.read_text()
                    return self.validate(spec_requirements, main_code)

            # Configure temporary database for validation (avoid global DATABASE_URL issues)
            # Use asyncpg driver to avoid psycopg2 async errors
            import os
            import sys
            import importlib

            # CRITICAL: Store and replace DATABASE_URL BEFORE any app imports
            original_database_url = os.environ.get('DATABASE_URL')

            # Fix DATABASE_URL if it exists but doesn't have asyncpg driver
            # This is critical because many environments set DATABASE_URL with postgresql://
            # but generated apps use AsyncSession which requires postgresql+asyncpg://
            if original_database_url and 'postgresql://' in original_database_url:
                if '+asyncpg' not in original_database_url:
                    # Convert postgresql:// to postgresql+asyncpg://
                    fixed_url = original_database_url.replace('postgresql://', 'postgresql+asyncpg://')
                    logger.info(f"Converting DATABASE_URL to async driver for validation")
                    os.environ['DATABASE_URL'] = fixed_url
                else:
                    # Already has asyncpg, use as is
                    pass
            else:
                # No DATABASE_URL or not PostgreSQL, set a dummy async URL
                # This won't actually connect during OpenAPI extraction
                os.environ['DATABASE_URL'] = 'postgresql+asyncpg://validation:validation@localhost/validation_temp'

            # Clear any existing modules from cache to avoid driver conflicts and cached settings
            # This is important because Settings uses @lru_cache and might have cached the old DATABASE_URL
            # CRITICAL: Save DevMatrix's 'src' module to restore it later
            devmatrix_src_module = sys.modules.get('src', None)

            # Clear all potentially conflicting modules INCLUDING 'src' base package
            modules_to_clear = [m for m in list(sys.modules.keys())
                              if any(pattern in m for pattern in ['psycopg', 'sqlalchemy', 'src.', 'src', 'api.', 'core.', 'models.'])]
            for module_name in modules_to_clear:
                sys.modules.pop(module_name, None)

            # Extra safety: Explicitly remove 'src' if it exists (DevMatrix namespace collision)
            sys.modules.pop('src', None)

            # Clear Prometheus metrics registry to avoid "Duplicated timeseries" errors
            # This happens when we import the app multiple times in the same Python process
            try:
                from prometheus_client import REGISTRY
                # Create a fresh registry by removing all collectors
                collectors = list(REGISTRY._collector_to_names.keys())
                for collector in collectors:
                    try:
                        REGISTRY.unregister(collector)
                    except Exception:
                        pass  # Ignore if unregister fails
            except ImportError:
                pass  # prometheus_client not available, that's fine

            try:
                # Load main.py as module with proper package context
                app_root = str(output_path)

                # Store original sys.path and cwd for cleanup
                original_sys_path = sys.path.copy()
                original_cwd = os.getcwd()

                # CRITICAL: Add app root to sys.path FIRST (highest priority)
                # This allows Python to find the 'src' package
                if app_root in sys.path:
                    sys.path.remove(app_root)  # Remove if exists to re-add at position 0
                sys.path.insert(0, app_root)

                # Store original working directory but DON'T change it yet
                # Changing cwd breaks relative imports in the generated app
                logger.debug(f"App root added to sys.path[0]: {sys.path[0]}")
                logger.debug(f"Current working directory: {os.getcwd()}")

                # Verify files exist (log for debugging)
                src_init = os.path.join(app_root, 'src', '__init__.py')
                src_main = os.path.join(app_root, 'src', 'main.py')
                logger.debug(f"src/__init__.py exists: {os.path.exists(src_init)}")
                logger.debug(f"src/main.py exists: {os.path.exists(src_main)}")

                # Import main module (either 'main' from root or 'src.main' from src/)
                # The app_root in sys.path[0] should be enough
                if is_root_main:
                    # main.py is in root - import as 'main'
                    main_module = __import__('main')
                else:
                    # main.py is in src/ - import as 'src.main'
                    main_module = __import__('src.main', fromlist=['app'])

                # Get FastAPI app instance immediately (while sys.path is still valid)
                app = main_module.app

                logger.info("Successfully imported FastAPI app")

                # Extract OpenAPI schema (while app is still accessible)
                openapi_schema = app.openapi()

            finally:
                # CRITICAL: Restore working directory FIRST (even if exception occurred)
                # This must be in finally block to prevent affecting subsequent operations
                try:
                    os.chdir(original_cwd)
                except:
                    pass  # Ignore if restoration fails

                # Restore original DATABASE_URL
                if original_database_url is not None:
                    os.environ['DATABASE_URL'] = original_database_url
                else:
                    os.environ.pop('DATABASE_URL', None)

                # Cleanup: Remove app_root from sys.path if we added it
                if app_root in sys.path:
                    sys.path.remove(app_root)

                # Cleanup: Clear lru_cache from get_settings() to avoid stale config
                # This is critical because get_settings() caches the Settings object,
                # and if we reimport modules later, we want fresh settings
                if 'src.core.config' in sys.modules:
                    try:
                        config_module = sys.modules['src.core.config']
                        if hasattr(config_module, 'get_settings'):
                            config_module.get_settings.cache_clear()
                    except Exception:
                        pass  # Ignore if cache_clear fails

                # Cleanup: Remove imported src.* modules from cache to avoid pollution
                modules_to_remove = [k for k in sys.modules.keys() if k.startswith('src.')]
                for module_name in modules_to_remove:
                    sys.modules.pop(module_name, None)

                # CRITICAL: Restore DevMatrix's 'src' module so rest of pipeline can import from it
                if devmatrix_src_module is not None:
                    sys.modules['src'] = devmatrix_src_module

            # 1. Extract entities from OpenAPI schemas
            # NOTE: Schemas might be empty (just 'pass') but we count them as present
            # since the structure exists even if fields are missing
            entities_found = []
            schemas = openapi_schema.get("components", {}).get("schemas", {})

            # Build set of expected entity names (lowercase for comparison)
            entities_expected_lower = {e.lower() for e in [ent.name for ent in spec_requirements.entities]}
            logger.debug(f"Looking for entities: {entities_expected_lower}")

            # Check all schemas and extract base entity names
            for schema_name in schemas.keys():
                # Remove common suffixes to get base entity name
                base_name = schema_name

                # Try removing suffixes in order (longest first)
                suffixes = ['Response', 'Create', 'Update', 'Entity', 'List', 'Base']
                for suffix in suffixes:
                    if base_name.endswith(suffix):
                        base_name = base_name[:-len(suffix)]
                        break

                # Check if this matches an expected entity (case-insensitive)
                if base_name.lower() in entities_expected_lower and base_name not in entities_found:
                    entities_found.append(base_name)
                    logger.debug(f"Found entity '{base_name}' from schema '{schema_name}'")

            logger.info(f"Extracted {len(entities_found)} entities from OpenAPI schemas: {entities_found}")

            # 1b. Extract entities directly from entities.py (more accurate - includes entities without endpoints)
            entities_file = output_path / "src" / "models" / "entities.py"
            if entities_file.exists():
                logger.debug(f"Reading entities directly from {entities_file}")
                entities_content = entities_file.read_text()

                # Find all class definitions: class XyzEntity(Base):
                import re
                entity_pattern = r'class\s+(\w+)Entity\(Base\):'
                entity_matches = re.findall(entity_pattern, entities_content)

                for entity_name in entity_matches:
                    if entity_name.lower() in entities_expected_lower and entity_name not in entities_found:
                        entities_found.append(entity_name)
                        logger.debug(f"Found entity '{entity_name}' from entities.py")

                logger.info(f"After checking entities.py: {len(entities_found)} entities found: {entities_found}")
            else:
                logger.warning(f"entities.py not found at {entities_file}")

            # 2. Extract endpoints from OpenAPI paths
            endpoints_found = []
            paths = openapi_schema.get("paths", {})

            for path, methods in paths.items():
                for method in methods.keys():
                    # Only include actual HTTP methods (not 'parameters', 'summary', etc.)
                    if method.upper() in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE', 'HEAD', 'OPTIONS']:
                        endpoints_found.append(f"{method.upper()} {path}")

            logger.info(f"Extracted {len(endpoints_found)} endpoints from OpenAPI paths")

            # 3. Extract validations (heuristic from schemas)
            validations_found = []
            for schema_name, schema_def in schemas.items():
                # Get base entity name (remove suffixes)
                base_entity_name = schema_name
                suffixes = ['Response', 'Create', 'Update', 'Entity', 'List', 'Base']
                for suffix in suffixes:
                    if base_entity_name.endswith(suffix):
                        base_entity_name = base_entity_name[:-len(suffix)]
                        break

                properties = schema_def.get("properties", {})
                for prop_name, prop_def in properties.items():
                    # Helper function to extract validations from a schema (handles anyOf)
                    def extract_validations(schema_obj, entity_name, field_name):
                        found_vals = []

                        # Check for validation constraints and capture in "Entity.field: constraint" format
                        if "exclusiveMinimum" in schema_obj and schema_obj.get("exclusiveMinimum") is not None:
                            constraint = f"gt={int(schema_obj['exclusiveMinimum'])}"
                            found_vals.append(f"{entity_name}.{field_name}: {constraint}")
                        elif "minimum" in schema_obj:
                            constraint = f"ge={int(schema_obj['minimum'])}"
                            found_vals.append(f"{entity_name}.{field_name}: {constraint}")

                        if "maximum" in schema_obj:
                            constraint = f"le={int(schema_obj['maximum'])}"
                            found_vals.append(f"{entity_name}.{field_name}: {constraint}")

                        if "minLength" in schema_obj or "maxLength" in schema_obj:
                            found_vals.append(f"{entity_name}.{field_name}: length")

                        if "pattern" in schema_obj:
                            pattern = schema_obj["pattern"]
                            found_vals.append(f"{entity_name}.{field_name}: pattern={pattern}")

                        if schema_obj.get("format") == "email":
                            found_vals.append(f"{entity_name}.{field_name}: email")

                        return found_vals

                    # Extract validations from prop_def directly
                    validations_found.extend(extract_validations(prop_def, base_entity_name, prop_name))

                    # Also check inside anyOf (for Decimal fields that can be number or string)
                    if "anyOf" in prop_def:
                        for sub_schema in prop_def["anyOf"]:
                            if isinstance(sub_schema, dict):
                                validations_found.extend(extract_validations(sub_schema, base_entity_name, prop_name))

            logger.info(f"Extracted {len(validations_found)} validations from OpenAPI schemas")

            # 3b. Extract validations directly from schemas.py (more accurate - includes schemas without endpoints)
            schemas_file = output_path / "src" / "models" / "schemas.py"
            if schemas_file.exists():
                logger.debug(f"Reading validations directly from {schemas_file}")
                schemas_content = schemas_file.read_text()

                # Find Field() validations: Field(..., gt=0), Field(..., ge=0), etc.
                # Pattern: field_name: Type = Field(..., constraint)
                import re

                # Match patterns like: quantity: int = Field(..., gt=0)
                # Updated to include min_length, max_length, lt and other common validators
                field_pattern = r'(\w+):\s*(?:Optional\[)?(\w+)(?:\])?\s*=\s*Field\([^)]*?(gt=\d+|ge=\d+|le=\d+|lt=\d+|min_length=\d+|max_length=\d+|pattern=|email)[^)]*\)'

                # Also track current class to know which entity
                class_pattern = r'class\s+(\w+)(?:Base|Create|Update|Response)\(BaseModel\):'

                current_entity = None
                for line in schemas_content.split('\n'):
                    # Check for class definition
                    class_match = re.match(class_pattern, line)
                    if class_match:
                        current_entity = class_match.group(1)
                        continue

                    # Check for field with validation
                    if current_entity:
                        field_match = re.search(field_pattern, line)
                        if field_match:
                            field_name = field_match.group(1)
                            constraint = field_match.group(3)

                            # Format: "Entity.field: constraint"
                            validation_sig = f"{current_entity}.{field_name}: {constraint}"

                            # Check if this matches an expected entity (case-insensitive)
                            if current_entity.lower() in entities_expected_lower and validation_sig not in validations_found:
                                validations_found.append(validation_sig)
                                logger.debug(f"Found validation '{validation_sig}' from schemas.py")

                logger.info(f"After checking schemas.py: {len(validations_found)} validations found")
            else:
                logger.warning(f"schemas.py not found at {schemas_file}")

            # 4. Extract what was expected from spec
            entities_expected = [e.name for e in spec_requirements.entities]
            endpoints_expected = [f"{ep.method} {ep.path}" for ep in spec_requirements.endpoints]

            # For validations, use ground truth if available, otherwise fallback to old logic
            validations_expected = []

            if spec_requirements.validation_ground_truth and 'validations' in spec_requirements.validation_ground_truth:
                # Use ground truth validations
                for val_id, val_data in spec_requirements.validation_ground_truth['validations'].items():
                    entity = val_data.get('entity', '')
                    field = val_data.get('field', '')
                    constraint = val_data.get('constraint', '')
                    # Format: "Entity.field: constraint"
                    validations_expected.append(f"{entity}.{field}: {constraint}")
                logger.info(f"Using validation ground truth: {len(validations_expected)} validations expected")
            else:
                # Fallback to old logic (business_logic + entity constraints)
                for bl in spec_requirements.business_logic:
                    if bl.type == "validation":
                        validations_expected.append(bl.description)

                # Add entity field constraints as expected validations
                for entity in spec_requirements.entities:
                    for field in entity.fields:
                        if field.constraints:
                            validations_expected.extend(field.constraints)

                # If no explicit validations, use a minimum count based on entities
                if not validations_expected and entities_expected:
                    # Expect at least 2 validations per entity (heuristic)
                    validations_expected = [f"validation_{i}" for i in range(len(entities_expected) * 2)]

            # 5. Calculate compliance per category
            entity_compliance = self._calculate_compliance(entities_found, entities_expected)
            endpoint_compliance = self._calculate_endpoint_compliance_fuzzy(endpoints_found, endpoints_expected)

            # Use exact matching if ground truth is available, otherwise use flexible matching
            use_exact_matching = bool(spec_requirements.validation_ground_truth and 'validations' in spec_requirements.validation_ground_truth)
            validation_compliance, validations_matched = self._calculate_validation_compliance(
                validations_found, validations_expected, use_exact_matching=use_exact_matching
            )

            # 6. Calculate overall compliance (weighted average)
            # Entities and endpoints are more important than validations
            overall_compliance = (
                entity_compliance * 0.40 + endpoint_compliance * 0.40 + validation_compliance * 0.20
            )

            # 7. Identify missing requirements
            missing = self._identify_missing_requirements(
                entities_expected,
                entities_found,
                endpoints_expected,
                endpoints_found,
                spec_requirements,
            )

            # 8. Build detailed report
            # Use matched validations (not all found) when ground truth exists for accurate metrics
            report = ComplianceReport(
                overall_compliance=overall_compliance,
                entities_implemented=entities_found,
                entities_expected=entities_expected,
                endpoints_implemented=endpoints_found,
                endpoints_expected=endpoints_expected,
                validations_implemented=validations_matched,  # Only matched validations, not all found
                validations_expected=validations_expected,
                missing_requirements=missing,
                compliance_details={
                    "entities": entity_compliance,
                    "endpoints": endpoint_compliance,
                    "validations": validation_compliance,
                },
            )

            logger.info(
                f"OpenAPI-based compliance validation complete: {overall_compliance:.1%} "
                f"(entities: {entity_compliance:.1%}, "
                f"endpoints: {endpoint_compliance:.1%}, "
                f"validations: {validation_compliance:.1%})"
            )

            return report

        except Exception as e:
            logger.error(f"Error importing app for OpenAPI validation: {e}")
            import traceback
            traceback.print_exc()

            # Fallback to old validation method
            logger.warning("Falling back to string-based validation (will show low compliance)")
            main_code = ""
            if (output_path / "src" / "main.py").exists():
                main_code = (output_path / "src" / "main.py").read_text()
            return self.validate(spec_requirements, main_code)

        finally:
            # Clean up sys.path
            if output_path_str in sys.path:
                sys.path.remove(output_path_str)

    def validate_or_raise(
        self, spec_requirements: SpecRequirements, generated_code: str, threshold: float = 0.80
    ) -> ComplianceReport:
        """
        Validate and raise exception if compliance below threshold

        Args:
            spec_requirements: Parsed specification
            generated_code: Generated Python code
            threshold: Minimum compliance score (default 0.80 = 80%)

        Returns:
            ComplianceReport if compliance >= threshold

        Raises:
            ComplianceValidationError: If compliance < threshold
        """
        report = self.validate(spec_requirements, generated_code)

        if report.overall_compliance < threshold:
            error_msg = (
                f"Compliance validation FAILED: {report.overall_compliance:.1%} "
                f"(threshold: {threshold:.1%})\n\n"
                f"{report}"
            )
            logger.error(error_msg)
            raise ComplianceValidationError(error_msg)

        logger.info(f"Compliance validation PASSED: {report.overall_compliance:.1%}")
        return report

    def _calculate_compliance(self, found: List[str], expected: List[str]) -> float:
        """
        Calculate compliance score for a category

        Uses set intersection to handle case variations and extra items.

        Args:
            found: Items found in generated code
            expected: Items expected from spec

        Returns:
            Compliance score 0.0-1.0
        """
        if not expected:
            return 1.0  # No requirements = 100% compliance

        if not found:
            return 0.0  # Nothing implemented = 0% compliance

        # Normalize for comparison (case-insensitive, strip whitespace)
        found_normalized = {item.strip().lower() for item in found}
        expected_normalized = {item.strip().lower() for item in expected}

        # Count how many expected items were found
        matches = found_normalized & expected_normalized
        compliance = len(matches) / len(expected_normalized)

        return min(compliance, 1.0)  # Cap at 100%

    def _calculate_endpoint_compliance_fuzzy(self, found: List[str], expected: List[str]) -> float:
        """
        Calculate endpoint compliance with fuzzy matching

        Fuzzy matching handles:
        1. Path parameter variations: /carts/{id} â‰ˆ /carts/{customer_id}
        2. Functionally equivalent HTTP methods: POST vs DELETE for "clear/empty"
        3. Route variations: /carts/clear â‰ˆ /carts/{id} for clear operations

        Args:
            found: Endpoints found in generated code (format: "GET /products")
            expected: Endpoints expected from spec

        Returns:
            Compliance score 0.0-1.0
        """
        if not expected:
            return 1.0

        if not found:
            return 0.0

        # Parse endpoints into (method, path) tuples
        def parse_endpoint(endpoint_str: str):
            parts = endpoint_str.strip().split(maxsplit=1)
            if len(parts) == 2:
                return parts[0].upper(), parts[1]
            return None, None

        expected_parsed = []
        for exp in expected:
            method, path = parse_endpoint(exp)
            if method and path:
                expected_parsed.append((method, path))

        found_parsed = []
        for fnd in found:
            method, path = parse_endpoint(fnd)
            if method and path:
                found_parsed.append((method, path))

        # Count fuzzy matches
        matches = 0
        for exp_method, exp_path in expected_parsed:
            if self._is_fuzzy_endpoint_match(exp_method, exp_path, found_parsed):
                matches += 1

        compliance = matches / len(expected_parsed) if expected_parsed else 0.0

        logger.debug(
            f"Endpoint fuzzy matching: {matches}/{len(expected_parsed)} matches "
            f"({compliance:.1%})"
        )

        return min(compliance, 1.0)

    def _is_fuzzy_endpoint_match(
        self,
        expected_method: str,
        expected_path: str,
        found_endpoints: List[tuple]
    ) -> bool:
        """
        Check if expected endpoint matches any found endpoint using fuzzy rules

        Args:
            expected_method: Expected HTTP method (GET, POST, etc.)
            expected_path: Expected path (/carts/{customer_id})
            found_endpoints: List of (method, path) tuples from generated code

        Returns:
            True if a fuzzy match is found
        """
        # Normalize paths: replace {any_param} with {id} for comparison
        def normalize_path(path: str) -> str:
            import re
            # Replace all {param_name} with {*} for fuzzy matching
            return re.sub(r'\{[^}]+\}', '{*}', path.lower().strip())

        expected_path_norm = normalize_path(expected_path)

        for found_method, found_path in found_endpoints:
            found_path_norm = normalize_path(found_path)

            # 1. Exact match (method + normalized path)
            if expected_method == found_method and expected_path_norm == found_path_norm:
                return True

            # 2. Functionally equivalent methods for specific operations
            if self._are_methods_functionally_equivalent(
                expected_method, found_method, expected_path, found_path
            ):
                # Check if paths are semantically similar
                if self._are_paths_similar(expected_path, found_path):
                    return True

        return False

    def _are_methods_functionally_equivalent(
        self,
        method1: str,
        method2: str,
        path1: str,
        path2: str
    ) -> bool:
        """
        Check if two HTTP methods are functionally equivalent for the operation

        Examples:
        - DELETE /carts/{id} â‰ˆ POST /carts/clear (both clear/empty cart)
        - PUT /orders/{id}/cancel â‰ˆ POST /orders/cancel (both cancel order)

        Args:
            method1, method2: HTTP methods to compare
            path1, path2: Paths to provide context

        Returns:
            True if methods are functionally equivalent
        """
        # Normalize methods
        m1, m2 = method1.upper(), method2.upper()

        # If methods are the same, they're equivalent
        if m1 == m2:
            return True

        # Check for clear/empty/delete operations
        if "clear" in path1.lower() or "clear" in path2.lower():
            # POST /carts/clear â‰ˆ DELETE /carts/{id}
            if {m1, m2} == {"POST", "DELETE"}:
                return True

        # Check for cancel operations
        if "cancel" in path1.lower() or "cancel" in path2.lower():
            # POST /orders/cancel â‰ˆ PUT /orders/{id}/cancel
            if {m1, m2} <= {"POST", "PUT", "PATCH"}:
                return True

        return False

    def _are_paths_similar(self, path1: str, path2: str) -> bool:
        """
        Check if two paths are semantically similar

        Examples:
        - /carts/{id} â‰ˆ /carts/{customer_id}
        - /carts/clear â‰ˆ /carts/{id} (for delete/clear operations)
        - /orders/{id}/cancel â‰ˆ /orders/cancel

        Args:
            path1, path2: Paths to compare

        Returns:
            True if paths are similar enough
        """
        import re

        # Normalize: lowercase, strip slashes
        p1 = path1.lower().strip().strip('/')
        p2 = path2.lower().strip().strip('/')

        # Exact match
        if p1 == p2:
            return True

        # Replace all {params} with placeholder for comparison
        p1_norm = re.sub(r'\{[^}]+\}', 'PARAM', p1)
        p2_norm = re.sub(r'\{[^}]+\}', 'PARAM', p2)

        # Match if normalized paths are the same
        if p1_norm == p2_norm:
            return True

        # Check for clear/cancel variations
        # /carts/{id} â‰ˆ /carts/clear
        p1_parts = p1_norm.split('/')
        p2_parts = p2_norm.split('/')

        if len(p1_parts) == len(p2_parts):
            # Same base path and either both have PARAM or one has clear/cancel
            if p1_parts[:-1] == p2_parts[:-1]:
                last1, last2 = p1_parts[-1], p2_parts[-1]
                if 'PARAM' in {last1, last2} and any(
                    x in {last1, last2} for x in ['clear', 'cancel', 'checkout']
                ):
                    return True

        return False

    def _calculate_validation_compliance(self, found: List[str], expected: List[str], use_exact_matching: bool = False) -> tuple[float, List[str]]:
        """
        Calculate validation compliance with exact or flexible matching

        When ground truth is available (use_exact_matching=True), we use exact string matching
        on "Entity.field: constraint" format. Otherwise, we use keyword matching.

        Args:
            found: Validation signatures found in code
            expected: Validation requirements from spec
            use_exact_matching: If True, use exact string matching (for ground truth)

        Returns:
            Tuple of (compliance_score 0.0-1.0, list of matched validation strings)
        """
        if not expected:
            return 1.0, found  # No expectations, all found validations count

        if not found:
            return 0.0, []  # Nothing found, no matches

        # EXACT MATCHING MODE (for ground truth)
        if use_exact_matching:
            # Expected format: "Entity.field: constraint" (e.g., "Product.price: gt=0")
            # Count how many expected validations are found in code
            matches = 0
            matched_validations = []

            for exp_val in expected:
                # Check if this validation exists in found
                # We need flexible matching on the format because found might have variations
                # Expected: "Product.price: gt=0"
                # Found could be: "Product.price: Field(gt=0)" or similar

                # Extract entity.field and constraint from expected
                if ": " in exp_val:
                    entity_field, constraint = exp_val.split(": ", 1)
                    # Check if any found validation contains this entity.field and constraint
                    for found_val in found:
                        if entity_field in found_val and constraint in found_val:
                            matches += 1
                            matched_validations.append(exp_val)  # Add the expected format, not found format
                            break

            compliance = matches / len(expected)
            logger.debug(f"Exact matching: {matches}/{len(expected)} validations found = {compliance:.2%}")
            logger.debug(f"Matched validations: {matched_validations}")
            return min(compliance, 1.0), matched_validations

        # FLEXIBLE KEYWORD MATCHING MODE (fallback for no ground truth)
        # Count validation types present
        validation_types = {
            "price": any("price" in v.lower() for v in found),
            "stock": any("stock" in v.lower() for v in found),
            "email": any("email" in v.lower() for v in found),
            "quantity": any("quantity" in v.lower() for v in found),
            "field": any("field" in v.lower() for v in found),
            "validation": any("validation" in v.lower() for v in found),
        }

        # Count how many validation types are expected
        expected_types = {
            "price": any("price" in v.lower() for v in expected),
            "stock": any("stock" in v.lower() for v in expected),
            "email": any("email" in v.lower() for v in expected),
            "quantity": any("quantity" in v.lower() for v in expected),
            "field": any("gt" in v.lower() or "ge" in v.lower() for v in expected),
            "validation": True,  # Always expect some validation
        }

        # Calculate match ratio
        matches = sum(
            1
            for key in validation_types
            if validation_types[key] and expected_types.get(key, False)
        )
        total_expected = sum(1 for val in expected_types.values() if val)

        if total_expected == 0:
            return 1.0, found  # No expectations, all found validations count

        compliance = matches / total_expected

        # Minimum score based on presence of any validations
        if found:
            compliance = max(compliance, 0.3)  # At least 30% if any validations exist

        # For flexible matching, return all found validations since we can't precisely match
        return min(compliance, 1.0), found

    def _identify_missing_requirements(
        self,
        entities_expected: List[str],
        entities_found: List[str],
        endpoints_expected: List[str],
        endpoints_found: List[str],
        spec: SpecRequirements,
    ) -> List[str]:
        """
        Identify specific missing requirements

        Args:
            entities_expected: Expected entity names
            entities_found: Found entity names
            endpoints_expected: Expected endpoints
            endpoints_found: Found endpoints
            spec: Full spec requirements

        Returns:
            List of missing requirement descriptions
        """
        missing = []

        # Missing entities
        entities_found_normalized = {e.lower() for e in entities_found}
        for entity in entities_expected:
            if entity.lower() not in entities_found_normalized:
                missing.append(f"Entity: {entity}")

        # Missing endpoints (sample first 5 to avoid spam)
        endpoints_found_normalized = {e.lower() for e in endpoints_found}
        missing_endpoints = []
        for endpoint in endpoints_expected:
            if endpoint.lower() not in endpoints_found_normalized:
                missing_endpoints.append(f"Endpoint: {endpoint}")

        # Add sample of missing endpoints
        missing.extend(missing_endpoints[:5])
        if len(missing_endpoints) > 5:
            missing.append(f"... and {len(missing_endpoints) - 5} more endpoints")

        # Missing functional requirements (sample)
        for req in spec.requirements[:5]:
            if req.type == "functional":
                # Check if requirement keywords are in code (heuristic)
                # This is a simplified check
                missing.append(f"Requirement {req.id}: {req.description[:60]}...")

        return missing

    def _format_entity_report(
        self,
        report: ComplianceReport
    ) -> str:
        """
        Enhanced entity report with categorization

        Separates:
        - Domain entities (Product, Customer, etc.)
        - Request/Response schemas (ProductCreate, etc.)
        - Enums (Status enums)

        Args:
            report: ComplianceReport with entities data

        Returns:
            Formatted string with categorized entities

        Part of Task Group 2: Presentation Enhancement (M4)
        """
        # Categorize entities
        domain_entities = []
        schemas = []
        enums = []

        for entity in report.entities_implemented:
            if entity in report.entities_expected:
                domain_entities.append(entity)
            elif entity.endswith(('Create', 'Update', 'Request', 'Response')):
                schemas.append(entity)
            elif entity.endswith('Status'):
                enums.append(entity)
            else:
                # Unknown category - treat as domain entity
                domain_entities.append(entity)

        # Format output
        lines = []
        lines.append(f"\nðŸ“¦ Entities ({len(report.entities_expected)} required, {len(domain_entities)} present):")
        lines.append(f"   âœ… {', '.join(domain_entities)}")

        if schemas or enums:
            lines.append(f"\n   ðŸ“ Additional models (best practices):")
            if schemas:
                lines.append(f"   - Request/Response schemas: {len(schemas)}")
            if enums:
                lines.append(f"   - Enums: {len(enums)}")

        return "\n".join(lines)

    def _format_endpoint_report(
        self,
        report: ComplianceReport
    ) -> str:
        """
        Enhanced endpoint report with categorization

        Separates:
        - Required endpoints (from spec)
        - Additional endpoints (best practices like / and /health)

        Args:
            report: ComplianceReport with endpoints data

        Returns:
            Formatted string with categorized endpoints

        Part of Task Group 2: Presentation Enhancement (M4)
        """
        # Categorize endpoints
        required_endpoints = []
        additional_endpoints = []

        for endpoint in report.endpoints_implemented:
            if endpoint in report.endpoints_expected:
                required_endpoints.append(endpoint)
            else:
                # Additional endpoints (best practices)
                additional_endpoints.append(endpoint)

        # Format output
        lines = []
        lines.append(f"\nðŸŒ Endpoints ({len(report.endpoints_expected)} required, {len(required_endpoints)} present):")
        
        if required_endpoints:
            # Show sample of required endpoints (first 5)
            sample = required_endpoints[:5]
            lines.append(f"   âœ… {', '.join(sample)}")
            if len(required_endpoints) > 5:
                lines.append(f"   ... and {len(required_endpoints) - 5} more")
        else:
            lines.append(f"   âŒ No required endpoints found")

        if additional_endpoints:
            lines.append(f"\n   ðŸ“ Additional endpoints (best practices):")
            for endpoint in additional_endpoints:
                lines.append(f"   - {endpoint}")

        return "\n".join(lines)

    def generate_detailed_report(
        self, spec_requirements: SpecRequirements, generated_code: str
    ) -> Dict[str, Any]:
        """
        Generate comprehensive compliance report with all details

        Args:
            spec_requirements: Parsed specification
            generated_code: Generated code

        Returns:
            Dict with full compliance analysis
        """
        report = self.validate(spec_requirements, generated_code)
        stats = self.analyzer.get_code_statistics(generated_code)

        detailed_report = {
            "compliance": {
                "overall": report.overall_compliance,
                "entities": report.compliance_details["entities"],
                "endpoints": report.compliance_details["endpoints"],
                "validations": report.compliance_details["validations"],
            },
            "entities": {
                "expected": report.entities_expected,
                "implemented": report.entities_implemented,
                "missing": [
                    e for e in report.entities_expected if e not in report.entities_implemented
                ],
            },
            "endpoints": {
                "expected_count": len(report.endpoints_expected),
                "implemented_count": len(report.endpoints_implemented),
                "sample_expected": report.endpoints_expected[:5],
                "sample_implemented": report.endpoints_implemented[:5],
            },
            "validations": {
                "expected_count": len(report.validations_expected),
                "implemented_count": len(report.validations_implemented),
                "types_found": report.validations_implemented,
            },
            "code_statistics": stats,
            "missing_requirements": report.missing_requirements,
            "passed": report.overall_compliance >= 0.80,
        }

        return detailed_report
