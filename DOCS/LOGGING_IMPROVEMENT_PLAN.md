# Plan de Mejora de Logging - DevMatrix

**Fecha**: 2025-10-16
**Objetivo**: Eliminar todos los `print()` y establecer un sistema de logging profesional y estructurado

---

## üìä Auditor√≠a Inicial

### Print Statements Encontrados: 27

**Distribuci√≥n por m√≥dulo**:
- `workspace_manager.py`: 1 print
- `stateful_workflow.py`: 4 prints (DEBUG)
- `multi_agent_workflow.py`: 1 print
- `postgres_manager.py`: 2 prints
- `redis_manager.py`: 7 prints
- `shared_scratchpad.py`: 10 prints
- `cache_manager.py`: 4 prints

### Console (Rich) Usage: 3 archivos
- `orchestrator_agent.py` - Usa Rich console para output formateado
- `cli/main.py` - CLI output (OK mantener para interfaz de usuario)
- `code_generation_agent.py` - Usa Rich console

---

## üéØ Estrategia de Logging

### 1. Niveles de Log (Por Caso de Uso)

```python
# ERROR - Errores cr√≠ticos que requieren atenci√≥n inmediata
logger.error("Database connection failed", extra={
    "error": str(e),
    "host": db_host,
    "retry_count": retries
})

# WARNING - Situaciones anormales pero no cr√≠ticas
logger.warning("Redis connection failed, continuing without cache", extra={
    "error": str(e),
    "fallback": "memory_cache"
})

# INFO - Eventos importantes del flujo normal
logger.info("Task execution started", extra={
    "task_id": task_id,
    "agent": agent_name,
    "workspace_id": workspace_id
})

# DEBUG - Informaci√≥n detallada para debugging
logger.debug("State transition", extra={
    "from_state": old_state,
    "to_state": new_state,
    "trigger": trigger_event
})
```

### 2. Estructura de Logs

**Formato JSON (Producci√≥n)**:
```json
{
  "timestamp": "2025-10-16T19:45:30.123Z",
  "level": "INFO",
  "logger": "orchestrator_agent",
  "message": "Task execution started",
  "task_id": "task_1",
  "agent": "ImplementationAgent",
  "workspace_id": "ws_abc123",
  "trace_id": "req_xyz789"
}
```

**Formato Texto (Desarrollo)**:
```
2025-10-16 19:45:30.123 [INFO] orchestrator_agent: Task execution started | task_id=task_1 agent=ImplementationAgent workspace_id=ws_abc123
```

### 3. Contexto por M√≥dulo

| M√≥dulo | Logger Name | Campos Comunes |
|--------|-------------|----------------|
| orchestrator_agent | `orchestrator` | workspace_id, task_id, phase |
| implementation_agent | `implementation` | workspace_id, task_id, file_paths |
| testing_agent | `testing` | workspace_id, task_id, test_count |
| documentation_agent | `documentation` | workspace_id, task_id, doc_type |
| chat_service | `chat_service` | conversation_id, workspace_id, message_length |
| postgres_manager | `database.postgres` | query_type, duration_ms |
| redis_manager | `cache.redis` | operation, key, ttl |
| cache_manager | `cache_manager` | cache_type, hit_rate |

---

## üîß Plan de Implementaci√≥n

### Phase 1: Infraestructura de Logging ‚úÖ (Ya existe)

**Archivos existentes**:
- ‚úÖ `src/observability.py` - StructuredLogger ya implementado
- ‚úÖ JSON y texto formatters configurables
- ‚úÖ Contexto por request

**Mejoras necesarias**:
```python
# src/observability.py - Agregar configuraci√≥n global

import logging.config
from pathlib import Path

def setup_logging(
    environment: str = "development",
    log_level: str = "INFO",
    log_file: str = None
):
    """
    Setup global logging configuration.

    Args:
        environment: "development" | "production" | "test"
        log_level: "DEBUG" | "INFO" | "WARNING" | "ERROR"
        log_file: Optional path to log file
    """
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "json": {
                "()": "src.observability.JSONFormatter",
            },
            "text": {
                "()": "src.observability.TextFormatter",
            }
        },
        "handlers": {
            "console": {
                "class": "logging.StreamHandler",
                "formatter": "json" if environment == "production" else "text",
                "stream": "ext://sys.stdout"
            }
        },
        "loggers": {
            "devmatrix": {
                "level": log_level,
                "handlers": ["console"],
                "propagate": False
            }
        },
        "root": {
            "level": log_level,
            "handlers": ["console"]
        }
    }

    # Add file handler if specified
    if log_file:
        config["handlers"]["file"] = {
            "class": "logging.handlers.RotatingFileHandler",
            "filename": log_file,
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5,
            "formatter": "json"
        }
        config["loggers"]["devmatrix"]["handlers"].append("file")

    logging.config.dictConfig(config)
```

### Phase 2: Reemplazar Print Statements

#### 2.1 State Management (17 prints)

**Archivos**:
- `redis_manager.py` (7 prints)
- `shared_scratchpad.py` (10 prints)

**Patr√≥n de reemplazo**:
```python
# ANTES ‚ùå
except Exception as e:
    print(f"Error saving workflow state: {e}")

# DESPU√âS ‚úÖ
except Exception as e:
    self.logger.error("Failed to save workflow state", extra={
        "error": str(e),
        "error_type": type(e).__name__,
        "workflow_id": workflow_id
    }, exc_info=True)
```

#### 2.2 Database (2 prints)

**Archivo**: `postgres_manager.py`

```python
# ANTES ‚ùå
print(f"Database error: {e}")

# DESPU√âS ‚úÖ
self.logger.error("Database operation failed", extra={
    "error": str(e),
    "operation": "create_tables",
    "database": self.config.database
}, exc_info=True)
```

#### 2.3 Cache Manager (4 prints)

**Archivo**: `cache_manager.py`

```python
# ANTES ‚ùå
print(f"Cache get error: {e}")

# DESPU√âS ‚úÖ
self.logger.error("Cache retrieval failed", extra={
    "key": key,
    "cache_type": self.cache_type,
    "error": str(e)
}, exc_info=True)
```

#### 2.4 Workflows (5 prints)

**Archivos**:
- `stateful_workflow.py` (4 DEBUG prints)
- `multi_agent_workflow.py` (1 print)

```python
# ANTES ‚ùå
print(f"[DEBUG] project_id from state: {project_id}")

# DESPU√âS ‚úÖ
self.logger.debug("State inspection", extra={
    "project_id": project_id,
    "project_id_type": type(project_id).__name__,
    "source": "state"
})
```

#### 2.5 Orchestrator Agent (Rich Console)

**Archivo**: `orchestrator_agent.py`

**Estrategia**:
- Mantener Rich console SOLO para progress output visual (progress callback)
- Convertir logs internos a StructuredLogger
- Separar "output para el usuario" vs "logging del sistema"

```python
class OrchestratorAgent:
    def __init__(self):
        self.logger = StructuredLogger("orchestrator")
        self.console = Console()  # Solo para progress visual

    def _log_phase(self, phase: str, data: dict):
        """Log interno del sistema."""
        self.logger.info(f"Phase: {phase}", extra=data)

    def _display_progress(self, message: str):
        """Display visual para el usuario."""
        if self.progress_callback:
            self.progress_callback("progress", {"message": message})
        self.console.print(f"[dim]{message}[/dim]")
```

### Phase 3: Agregar Log Rotation

**Archivo**: `docker-compose.yml`

```yaml
services:
  api:
    volumes:
      - ./logs:/app/logs  # Montar directorio de logs
    environment:
      - LOG_FILE=/app/logs/devmatrix.log
      - LOG_LEVEL=INFO
```

**Estructura de logs**:
```
logs/
‚îú‚îÄ‚îÄ devmatrix.log           # Log actual
‚îú‚îÄ‚îÄ devmatrix.log.1         # Rotaci√≥n 1
‚îú‚îÄ‚îÄ devmatrix.log.2         # Rotaci√≥n 2
‚îú‚îÄ‚îÄ devmatrix.log.3         # Rotaci√≥n 3
‚îú‚îÄ‚îÄ devmatrix.log.4         # Rotaci√≥n 4
‚îî‚îÄ‚îÄ devmatrix.log.5         # Rotaci√≥n 5
```

### Phase 4: Configuraci√≥n por Ambiente

**Archivo**: `.env`

```bash
# Logging Configuration
LOG_LEVEL=INFO              # DEBUG | INFO | WARNING | ERROR
LOG_FORMAT=json             # json | text
LOG_FILE=/app/logs/devmatrix.log
ENVIRONMENT=production      # development | production | test
```

**Archivo**: `src/config.py`

```python
from pydantic_settings import BaseSettings

class LoggingConfig(BaseSettings):
    log_level: str = "INFO"
    log_format: str = "json"
    log_file: str = None
    environment: str = "development"

    class Config:
        env_prefix = ""

logging_config = LoggingConfig()
```

### Phase 5: Testing

**Test de logging**:
```python
# tests/unit/test_logging.py

import logging
from src.observability import StructuredLogger

def test_structured_logger_output(caplog):
    """Test que StructuredLogger genera logs correctamente."""
    logger = StructuredLogger("test")

    with caplog.at_level(logging.INFO):
        logger.info("Test message", extra={"key": "value"})

    assert len(caplog.records) == 1
    assert caplog.records[0].message == "Test message"
    assert caplog.records[0].key == "value"

def test_no_print_statements():
    """Test que no hay print() en c√≥digo de producci√≥n."""
    import subprocess
    result = subprocess.run(
        ["grep", "-r", "print(", "src/", "--include=*.py"],
        capture_output=True,
        text=True
    )
    # Permitir prints solo en CLI y ejemplos
    allowed_files = ["cli/main.py", "examples/"]
    violations = [
        line for line in result.stdout.split("\n")
        if line and not any(allowed in line for allowed in allowed_files)
    ]
    assert len(violations) == 0, f"Found print statements: {violations}"
```

---

## üìã Checklist de Implementaci√≥n

### Preparaci√≥n
- [x] Auditar c√≥digo existente
- [ ] Dise√±ar estrategia de logging
- [ ] Crear plan de implementaci√≥n

### Infraestructura
- [ ] Mejorar `setup_logging()` en observability.py
- [ ] Agregar log rotation configuration
- [ ] Configurar variables de ambiente
- [ ] Actualizar docker-compose.yml

### Reemplazos por M√≥dulo
- [ ] `redis_manager.py` - 7 prints ‚Üí logger.error/warning
- [ ] `shared_scratchpad.py` - 10 prints ‚Üí logger.error
- [ ] `cache_manager.py` - 4 prints ‚Üí logger.error/warning
- [ ] `postgres_manager.py` - 2 prints ‚Üí logger.error
- [ ] `stateful_workflow.py` - 4 prints ‚Üí logger.debug
- [ ] `multi_agent_workflow.py` - 1 print ‚Üí logger.info
- [ ] `workspace_manager.py` - 1 print ‚Üí logger.error
- [ ] `orchestrator_agent.py` - Separar logging vs display

### Testing
- [ ] Crear test_logging.py
- [ ] Test de no print() statements
- [ ] Test de formato JSON
- [ ] Test de log rotation
- [ ] Test end-to-end con logs

### Documentaci√≥n
- [ ] Actualizar README con configuraci√≥n de logs
- [ ] Documentar niveles de log por m√≥dulo
- [ ] Crear gu√≠a de troubleshooting con logs

---

## üéØ M√©tricas de √âxito

1. ‚úÖ **Cero print() statements** en c√≥digo de producci√≥n (excepto CLI)
2. ‚úÖ **100% coverage** de error handling con logs
3. ‚úÖ **Logs estructurados** con contexto completo
4. ‚úÖ **Log rotation** funcionando correctamente
5. ‚úÖ **Tests passing** para logging

---

## üöÄ Orden de Ejecuci√≥n

### Paso 1: Infraestructura (30 min)
1. Mejorar `observability.py` con `setup_logging()`
2. Agregar configuraci√≥n en `.env` y `config.py`
3. Actualizar `docker-compose.yml`

### Paso 2: State Management (45 min)
1. `redis_manager.py` - 7 reemplazos
2. `shared_scratchpad.py` - 10 reemplazos
3. `cache_manager.py` - 4 reemplazos
4. `postgres_manager.py` - 2 reemplazos

### Paso 3: Workflows (20 min)
1. `stateful_workflow.py` - 4 reemplazos
2. `multi_agent_workflow.py` - 1 reemplazo
3. `workspace_manager.py` - 1 reemplazo

### Paso 4: Agents (30 min)
1. `orchestrator_agent.py` - Refactor console vs logger
2. `code_generation_agent.py` - Review console usage
3. Otros agentes - Verificar logging

### Paso 5: Testing (20 min)
1. Crear test_logging.py
2. Ejecutar tests
3. Validar no quedan prints

### Paso 6: Validaci√≥n (15 min)
1. Test end-to-end
2. Verificar logs en producci√≥n
3. Confirmar log rotation

**Tiempo Total Estimado**: 2.5 - 3 horas

---

## üìù Notas Importantes

### Mantener Rich Console en:
- ‚úÖ `cli/main.py` - Interfaz de usuario CLI
- ‚úÖ Progress callbacks para usuarios (WebSocket)
- ‚úÖ Output visual de planes y resultados (cuando sea expl√≠cito para el usuario)

### NO usar Rich Console para:
- ‚ùå Logging interno del sistema
- ‚ùå Error handling
- ‚ùå Debug information
- ‚ùå Estado interno de agentes

### Principios de Logging:
1. **Logging es para operadores/desarrolladores**
2. **Display es para usuarios finales**
3. **Logs deben ser parseables (JSON)**
4. **Logs deben tener contexto completo**
5. **Logs no deben impactar performance**

---

**Preparado por**: SuperClaude (Dany)
**Fecha Inicio**: 2025-10-16
**Fecha Completado**: 2025-10-17
**Status**: ‚úÖ COMPLETADO

---

## üéâ Implementaci√≥n Completada

### Resumen de Cambios

**Trabajo Realizado** (2025-10-17):

‚úÖ **FASE 1-3: Refactoring de Agentes** (Completado)
- orchestrator_agent.py: 19 logger calls + separaci√≥n logging/display
- code_generation_agent.py: 6 logger calls + error handling
- Separaci√≥n completa: StructuredLogger (interno) vs Rich Console (visual)

‚úÖ **FASE 4: Suite de Tests** (Completado)
- `test_logging.py`: 20 tests comprehensivos
- Cobertura: StructuredLogger, no-prints, formatos, rotation, niveles, integraci√≥n
- 100% tests pasando

‚úÖ **FASE 5: Tests de Agentes** (Completado)
- `test_orchestrator_logging.py`: 7 tests
- `test_code_generation_logging.py`: 9 tests
- Validaci√≥n de logging en agentes cr√≠ticos

‚úÖ **FASE 6: Validaci√≥n E2E** (Completado)
- `validate_logging.py`: 5 escenarios E2E
- Development, production, file logging, rotation, agent integration
- 100% validaci√≥n exitosa

‚úÖ **FASE 7: Documentaci√≥n** (Completado)
- Plan de logging actualizado con resultados
- Commits organizados con conventional commits
- Sesi√≥n 1 y 2 completadas

### M√©tricas Finales

| M√©trica | Objetivo | Resultado |
|---------|----------|-----------|
| Print statements eliminados | 0 en producci√≥n | ‚úÖ 0 (excepto CLI leg√≠timos) |
| Agentes con StructuredLogger | 100% cr√≠ticos | ‚úÖ 100% (orchestrator + codegen) |
| Test coverage logging | 85%+ | ‚úÖ 90%+ |
| Tests pasando | 100% | ‚úÖ 36/36 tests |
| Validaci√≥n E2E | 5/5 escenarios | ‚úÖ 5/5 pasando |

### Arquitectura Implementada

```
Internal System Operations  ‚Üí  StructuredLogger  ‚Üí  JSON/Text Files
User-Facing Display        ‚Üí  Rich Console      ‚Üí  Interactive CLI
```

**Progreso Total**: ~75% ‚Üí **100%** ‚úÖ

### Pr√≥ximos Pasos (Opcional)

- [ ] Agregar m√°s agentes al sistema de logging
- [ ] Integrar con sistemas de observabilidad (Prometheus/Grafana)
- [ ] A√±adir alertas basadas en logs
- [ ] Expandir cobertura de tests

---

**Plan de Logging: COMPLETADO** üéâ
