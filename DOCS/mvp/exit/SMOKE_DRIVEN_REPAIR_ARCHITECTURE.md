# Smoke-Driven Repair Architecture

**Fecha:** 2025-11-29
**Estado:** DiseÃ±o Completo
**Referencia:** `DOCS/mvp/exit/debug/SMOKE_REPAIR_DISCONNECT.md`

---

## Overview

Esta arquitectura cierra el gap crÃ­tico entre smoke tests y code repair, habilitando un ciclo de mejora continua basado en pruebas de runtime reales.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SMOKE-DRIVEN REPAIR ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Code Generation â”€â”€â†’ Smoke Test â”€â”€â†’ Analyze Failures â”€â”€â†’ Repair â”€â”€â†’ Loop  â”‚
â”‚         â”‚                 â”‚                â”‚                 â”‚              â”‚
â”‚         â”‚                 â†“                â†“                 â†“              â”‚
â”‚         â”‚            Pass Rate        Violations        Fix Patterns       â”‚
â”‚         â”‚             < 80%?          + Stack Traces    Applied           â”‚
â”‚         â”‚                 â”‚                â”‚                 â”‚              â”‚
â”‚         â”‚                 â†“                â†“                 â†“              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Learning System â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                               â”‚                                             â”‚
â”‚                               â†“                                             â”‚
â”‚                    Next Generation Improved                                â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Componentes Principales

### 1. SmokeTestOrchestrator

**UbicaciÃ³n:** `src/validation/smoke_test_orchestrator.py` (NUEVO)

**Responsabilidad:** Coordinar el ciclo smokeâ†’repairâ†’smoke.

```python
@dataclass
class SmokeRepairConfig:
    """Configuration for smoke-driven repair."""
    max_iterations: int = 3
    target_pass_rate: float = 0.8
    enable_server_log_capture: bool = True
    enable_learning: bool = True


class SmokeTestOrchestrator:
    """
    Orchestrates the smoke test â†’ repair â†’ retest cycle.

    Flow:
    1. Run initial smoke test
    2. If pass_rate < target: trigger repair
    3. Repair based on violations
    4. Retest
    5. Repeat until pass_rate >= target or max_iterations
    6. Record learnings
    """

    def __init__(
        self,
        smoke_validator: RuntimeSmokeValidator,
        code_repair_agent: CodeRepairAgent,
        pattern_adapter: SmokeTestPatternAdapter,
        config: SmokeRepairConfig = None
    ):
        self.smoke_validator = smoke_validator
        self.code_repair_agent = code_repair_agent
        self.pattern_adapter = pattern_adapter
        self.config = config or SmokeRepairConfig()

    async def run_smoke_repair_cycle(
        self,
        app_path: Path,
        application_ir: ApplicationIR
    ) -> SmokeRepairResult:
        """
        Main entry point for smoke-driven repair.

        Returns comprehensive result including:
        - Final smoke test results
        - Repairs applied per iteration
        - Learning events generated
        - Improvement trajectory
        """
        iterations = []
        current_pass_rate = 0.0

        for i in range(self.config.max_iterations):
            # 1. Run smoke test
            smoke_result = await self.smoke_validator.run_smoke_test(
                app_path=app_path,
                capture_logs=self.config.enable_server_log_capture
            )

            current_pass_rate = smoke_result.pass_rate
            iterations.append(SmokeIteration(
                iteration=i + 1,
                pass_rate=current_pass_rate,
                violations=len(smoke_result.violations)
            ))

            # 2. Check if target reached
            if current_pass_rate >= self.config.target_pass_rate:
                break

            # 3. Repair based on violations
            repair_result = await self.code_repair_agent.repair_from_smoke(
                violations=smoke_result.violations,
                server_logs=smoke_result.server_logs,
                app_path=app_path
            )

            # 4. Record learnings
            if self.config.enable_learning:
                self.pattern_adapter.record_repair_attempt(
                    violations=smoke_result.violations,
                    repairs=repair_result.fixes_applied,
                    success=repair_result.success
                )

        return SmokeRepairResult(
            final_pass_rate=current_pass_rate,
            iterations=iterations,
            target_reached=current_pass_rate >= self.config.target_pass_rate,
            total_repairs=sum(it.repairs_applied for it in iterations)
        )
```

### 2. Enhanced RuntimeSmokeValidator

**UbicaciÃ³n:** `src/validation/runtime_smoke_validator.py` (MODIFICAR)

**Nuevas capacidades:**
- Captura de server logs
- ExtracciÃ³n de stack traces
- ClasificaciÃ³n de errores

```python
@dataclass
class EnhancedSmokeResult:
    """Extended smoke test result with diagnostics."""
    # Existing fields
    passed: bool
    pass_rate: float
    endpoints_tested: int
    endpoints_passed: int
    violations: List[SmokeViolation]

    # NEW fields
    server_logs: str
    stack_traces: List[StackTrace]
    error_classifications: Dict[str, List[str]]  # {endpoint: [error_types]}


@dataclass
class StackTrace:
    """Parsed stack trace from server logs."""
    endpoint: str
    error_type: str  # "500", "404", "422", "timeout"
    exception_class: str  # "IntegrityError", "ValidationError", etc.
    exception_message: str
    file_path: str
    line_number: int
    full_trace: str


class RuntimeSmokeValidator:
    async def run_smoke_test(
        self,
        app_path: Path,
        capture_logs: bool = True
    ) -> EnhancedSmokeResult:
        """Run smoke test with optional log capture."""

        # Start container with log capture
        container = await self._start_container(app_path)

        try:
            # Run scenarios
            results = await self._execute_scenarios(container)

            # Capture logs if enabled
            server_logs = ""
            stack_traces = []
            if capture_logs:
                server_logs = await self._get_container_logs(container)
                stack_traces = self._parse_stack_traces(server_logs)

            return EnhancedSmokeResult(
                passed=results.all_passed,
                pass_rate=results.pass_rate,
                # ... other fields ...
                server_logs=server_logs,
                stack_traces=stack_traces,
                error_classifications=self._classify_errors(stack_traces)
            )
        finally:
            await self._cleanup_container(container)

    def _parse_stack_traces(self, logs: str) -> List[StackTrace]:
        """Extract stack traces from server logs."""
        traces = []
        # Regex patterns for common Python exceptions
        traceback_pattern = r'Traceback \(most recent call last\):.*?(?=\n\n|\Z)'

        for match in re.finditer(traceback_pattern, logs, re.DOTALL):
            trace_text = match.group()
            traces.append(self._parse_single_trace(trace_text))

        return traces

    def _classify_errors(self, traces: List[StackTrace]) -> Dict[str, List[str]]:
        """Classify errors by type for targeted repair."""
        classifications = {
            "database": [],      # IntegrityError, OperationalError
            "validation": [],    # ValidationError, ValueError
            "import": [],        # ImportError, ModuleNotFoundError
            "attribute": [],     # AttributeError
            "type": [],          # TypeError
            "key": [],           # KeyError
            "other": []
        }

        for trace in traces:
            category = self._categorize_exception(trace.exception_class)
            classifications[category].append(trace.endpoint)

        return classifications
```

### 3. Smoke-Aware CodeRepairAgent

**UbicaciÃ³n:** `src/mge/v2/agents/code_repair_agent.py` (MODIFICAR)

**Nuevas capacidades:**
- Repair basado en stack traces
- Fix strategies por tipo de error
- Query de fix patterns previos

```python
class CodeRepairAgent:
    async def repair_from_smoke(
        self,
        violations: List[SmokeViolation],
        server_logs: str,
        app_path: Path
    ) -> RepairResult:
        """
        Repair code based on smoke test failures.

        Strategy selection based on error type:
        - 500 + IntegrityError â†’ Fix database constraints/nullability
        - 500 + ValidationError â†’ Fix Pydantic schema mismatches
        - 500 + AttributeError â†’ Fix missing imports/attributes
        - 404 â†’ Fix route registration
        - 422 â†’ Fix request body schema
        """
        repairs = []

        # Group violations by error classification
        by_type = self._group_by_error_type(violations, server_logs)

        for error_type, endpoints in by_type.items():
            strategy = self._get_repair_strategy(error_type)
            for endpoint in endpoints:
                fix = await strategy.apply(endpoint, app_path)
                if fix:
                    repairs.append(fix)

        return RepairResult(
            fixes_applied=repairs,
            success=len(repairs) > 0,
            files_modified=[r.file_path for r in repairs]
        )

    def _get_repair_strategy(self, error_type: str) -> RepairStrategy:
        """Get appropriate repair strategy for error type."""
        strategies = {
            "database": DatabaseRepairStrategy(),
            "validation": ValidationRepairStrategy(),
            "import": ImportRepairStrategy(),
            "attribute": AttributeRepairStrategy(),
            "route": RouteRepairStrategy(),
        }
        return strategies.get(error_type, GenericRepairStrategy())


class DatabaseRepairStrategy(RepairStrategy):
    """Fix database-related 500 errors."""

    async def apply(self, endpoint: str, app_path: Path) -> Optional[Fix]:
        """
        Common database fixes:
        1. Add nullable=True to optional columns
        2. Add default values
        3. Fix foreign key references
        4. Add missing indices
        """
        # Identify affected entity from endpoint
        entity = self._endpoint_to_entity(endpoint)

        # Check common issues
        fixes = []

        # Issue: Column not nullable but no default
        if await self._has_nullable_issue(entity, app_path):
            fixes.append(self._fix_nullable(entity, app_path))

        # Issue: Missing foreign key
        if await self._has_fk_issue(entity, app_path):
            fixes.append(self._fix_foreign_key(entity, app_path))

        return fixes[0] if fixes else None


class ValidationRepairStrategy(RepairStrategy):
    """Fix Pydantic validation errors."""

    async def apply(self, endpoint: str, app_path: Path) -> Optional[Fix]:
        """
        Common validation fixes:
        1. Add Optional[] to non-required fields
        2. Fix type mismatches (str vs int)
        3. Add field validators
        4. Fix enum values
        """
        # ... implementation
```

### 4. Fix Pattern Learning

**UbicaciÃ³n:** `src/validation/smoke_test_pattern_adapter.py` (EXTENDER)

**Nuevas capacidades:**
- Record de fix patterns exitosos
- Query de fixes para problemas similares
- AplicaciÃ³n automÃ¡tica de fixes conocidos

```python
@dataclass
class FixPattern:
    """A learned fix pattern from smoke-driven repair."""
    pattern_id: str
    error_type: str           # "database", "validation", etc.
    endpoint_pattern: str     # "POST /entities", "PUT /entities/{id}"
    exception_class: str      # "IntegrityError", "ValidationError"
    fix_type: str            # "add_nullable", "fix_import", etc.
    fix_template: str        # Code template to apply
    success_count: int
    failure_count: int
    success_rate: float


class SmokeTestPatternAdapter:
    def record_repair_attempt(
        self,
        violations: List[SmokeViolation],
        repairs: List[Fix],
        success: bool
    ):
        """
        Record fix attempt for learning.

        If successful:
        - Increment success_count for matching pattern
        - Update success_rate
        - Consider for promotion

        If failed:
        - Increment failure_count
        - Consider for demotion
        """
        for repair in repairs:
            pattern = self._find_or_create_pattern(repair)

            if success:
                pattern.success_count += 1
            else:
                pattern.failure_count += 1

            pattern.success_rate = (
                pattern.success_count /
                (pattern.success_count + pattern.failure_count)
            )

            self._persist_pattern(pattern)

    def get_known_fix(
        self,
        error_type: str,
        endpoint_pattern: str,
        exception_class: str
    ) -> Optional[FixPattern]:
        """
        Query for known fix pattern with high success rate.

        Returns pattern if:
        - Matches error signature
        - success_rate >= 0.7
        - success_count >= 3 (enough evidence)
        """
        query = """
        MATCH (fp:FixPattern)
        WHERE fp.error_type = $error_type
          AND fp.endpoint_pattern = $endpoint_pattern
          AND fp.exception_class = $exception_class
          AND fp.success_rate >= 0.7
          AND fp.success_count >= 3
        RETURN fp
        ORDER BY fp.success_rate DESC
        LIMIT 1
        """
        # ... execute query
```

---

## Pipeline Integration

### Nuevo Flujo de Fases

```
Phase 6: Code Generation
    â†“
Phase 6.5: Code Repair (compliance-based) - PUEDE SKIPPEARSE
    â†“
Phase 7: Validation (semantic)
    â†“
Phase 8: Deployment
    â†“
Phase 8.5: Smoke-Repair Cycle (NUEVO)          â† Principal punto de repair
    â”œâ”€â”€ Run smoke test
    â”œâ”€â”€ If pass_rate < 80%:
    â”‚   â”œâ”€â”€ Capture server logs
    â”‚   â”œâ”€â”€ Parse stack traces
    â”‚   â”œâ”€â”€ Apply targeted repairs
    â”‚   â”œâ”€â”€ Retest
    â”‚   â””â”€â”€ Loop (max 3 iterations)
    â””â”€â”€ Record learnings
    â†“
Phase 9: Health Verification
    â†“
Phase 10: Learning & Promotion
```

### CÃ³digo de IntegraciÃ³n

```python
# tests/e2e/real_e2e_full_pipeline.py

async def _phase_8_5_smoke_repair(self):
    """Phase 8.5: Smoke-Driven Repair Cycle."""
    print("\nğŸ”¥ Phase 8.5: Smoke-Driven Repair")

    orchestrator = SmokeTestOrchestrator(
        smoke_validator=self.smoke_validator,
        code_repair_agent=self.code_repair_agent,
        pattern_adapter=self.smoke_pattern_adapter,
        config=SmokeRepairConfig(
            max_iterations=3,
            target_pass_rate=0.8,
            enable_server_log_capture=True,
            enable_learning=True
        )
    )

    result = await orchestrator.run_smoke_repair_cycle(
        app_path=self.output_path,
        application_ir=self.application_ir
    )

    # Report results
    print(f"\n  ğŸ“Š Smoke-Repair Results:")
    print(f"    - Initial pass rate: {result.iterations[0].pass_rate:.1%}")
    print(f"    - Final pass rate: {result.final_pass_rate:.1%}")
    print(f"    - Iterations: {len(result.iterations)}")
    print(f"    - Total repairs: {result.total_repairs}")
    print(f"    - Target reached: {'âœ…' if result.target_reached else 'âŒ'}")

    # Record in metrics
    self.metrics_collector.add_checkpoint("smoke_repair", "CP-8.5.COMPLETE", {
        "initial_pass_rate": result.iterations[0].pass_rate,
        "final_pass_rate": result.final_pass_rate,
        "iterations": len(result.iterations),
        "repairs_applied": result.total_repairs,
        "target_reached": result.target_reached
    })

    return result
```

---

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            DATA FLOW DIAGRAM                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  SmokeTest                                                                   â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â”œâ”€â”€ violations: [{endpoint, expected, actual, error}]                  â”‚
â”‚      â”œâ”€â”€ server_logs: "Traceback... IntegrityError..."                      â”‚
â”‚      â””â”€â”€ stack_traces: [{endpoint, exception_class, file, line}]            â”‚
â”‚              â”‚                                                               â”‚
â”‚              â†“                                                               â”‚
â”‚  ErrorClassifier                                                             â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â””â”€â”€ classifications: {                                                  â”‚
â”‚              "database": ["/products", "/customers"],                        â”‚
â”‚              "validation": ["/orders"],                                      â”‚
â”‚          }                                                                   â”‚
â”‚              â”‚                                                               â”‚
â”‚              â†“                                                               â”‚
â”‚  FixPatternStore (query known fixes)                                        â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â””â”€â”€ known_fixes: [FixPattern] or None                                  â”‚
â”‚              â”‚                                                               â”‚
â”‚              â†“                                                               â”‚
â”‚  RepairStrategy (apply fix)                                                 â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â””â”€â”€ Fix: {file_path, old_code, new_code, fix_type}                    â”‚
â”‚              â”‚                                                               â”‚
â”‚              â†“                                                               â”‚
â”‚  CodeRepairAgent (execute fix)                                              â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â””â”€â”€ RepairResult: {success, files_modified}                            â”‚
â”‚              â”‚                                                               â”‚
â”‚              â†“                                                               â”‚
â”‚  PatternAdapter (record learning)                                           â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â””â”€â”€ FixPattern: {success_count++, success_rate updated}               â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ©tricas y Monitoreo

### Nuevas MÃ©tricas

```python
@dataclass
class SmokeRepairMetrics:
    """Metrics for smoke-driven repair cycle."""

    # Pass rate trajectory
    initial_pass_rate: float
    final_pass_rate: float
    improvement: float  # final - initial

    # Repair effectiveness
    iterations_used: int
    repairs_attempted: int
    repairs_successful: int
    repair_success_rate: float

    # Error distribution
    errors_by_type: Dict[str, int]
    most_common_error: str

    # Learning
    new_patterns_discovered: int
    known_patterns_applied: int
    patterns_promoted: int

    # Timing
    total_duration_ms: int
    avg_iteration_ms: int
```

### Dashboard Output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SMOKE-DRIVEN REPAIR DASHBOARD                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ“ˆ Pass Rate Trajectory                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Iteration 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 56%                                â”‚
â”‚  Iteration 2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 72%                                â”‚
â”‚  Iteration 3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 85% âœ…                              â”‚
â”‚                                                                              â”‚
â”‚  ğŸ”§ Repairs Applied                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚
â”‚  Database fixes:    8 (IntegrityError, nullable)                            â”‚
â”‚  Validation fixes:  3 (Pydantic schema)                                     â”‚
â”‚  Import fixes:      2 (missing modules)                                     â”‚
â”‚  Route fixes:       1 (registration)                                        â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“ Learning                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                               â”‚
â”‚  New patterns:      4                                                        â”‚
â”‚  Applied known:     6                                                        â”‚
â”‚  Promoted:          2 (>70% success)                                        â”‚
â”‚                                                                              â”‚
â”‚  â±ï¸  Timing                                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                  â”‚
â”‚  Total: 45.2s (3 iterations Ã— ~15s each)                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Archivos Nuevos/Modificados

### Nuevos Archivos

| Archivo | DescripciÃ³n |
|---------|-------------|
| `src/validation/smoke_test_orchestrator.py` | Coordinador del ciclo smokeâ†’repair |
| `src/mge/v2/strategies/database_repair.py` | Strategy para fixes de DB |
| `src/mge/v2/strategies/validation_repair.py` | Strategy para fixes de validaciÃ³n |

### Archivos Modificados

| Archivo | Cambios |
|---------|---------|
| `src/validation/runtime_smoke_validator.py` | Server log capture, stack trace parsing |
| `src/mge/v2/agents/code_repair_agent.py` | `repair_from_smoke()` method |
| `src/validation/smoke_test_pattern_adapter.py` | FixPattern learning |
| `tests/e2e/real_e2e_full_pipeline.py` | Phase 8.5 integration |

---

## Advanced Features: Cognitive Software Engine

Estas mejoras elevan el sistema de "repair loop" a un **Cognitive Software Engine** con auto-reparaciÃ³n estructural.

### 2.1 Causal Repair Attribution

**Objetivo:** Mapear causalmente IR â†’ AST â†’ Failing Test para identificar la causa raÃ­z exacta.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAUSAL REPAIR ATTRIBUTION                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Failing Test                                                               â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â†“                                                                     â”‚
â”‚  POST /products â†’ 500 IntegrityError                                       â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â†“                                                                     â”‚
â”‚  AST Analysis                                                              â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â””â”€â”€ ProductCreate schema missing `price` validation                  â”‚
â”‚           â”‚                                                                â”‚
â”‚           â†“                                                                 â”‚
â”‚  IR Constraint Mismatch                                                    â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â””â”€â”€ IRConstraint: price > 0 (required)                               â”‚
â”‚           GeneratedConstraint: MISSING                                     â”‚
â”‚           â”‚                                                                â”‚
â”‚           â†“                                                                 â”‚
â”‚  Root Cause: ValidationModelIR â†’ Schema generation lost constraint         â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplementaciÃ³n:**

```python
@dataclass
class CausalChain:
    """Causal chain from failing test to IR root cause."""
    failing_test: str           # "POST /products [create_product_happy_path]"
    error_type: str             # "IntegrityError"
    ast_location: str           # "src/models/schemas.py:ProductCreate"
    ir_constraint: str          # "price > 0 (required)"
    generated_constraint: str   # "MISSING" or actual
    root_cause: str            # "ValidationModelIR â†’ Schema generation"
    confidence: float          # 0.0 - 1.0


class CausalAttributor:
    """
    Identifies causal chain from test failure to IR root cause.

    Algorithm:
    1. Parse failing test â†’ identify endpoint + entity
    2. AST parse generated code â†’ find constraint definitions
    3. Compare with IR constraints â†’ identify delta
    4. Attribute root cause to specific IRâ†’Code transformation
    """

    def attribute_failure(
        self,
        violation: SmokeViolation,
        stack_trace: StackTrace,
        application_ir: ApplicationIR,
        app_path: Path
    ) -> CausalChain:
        # 1. Extract entity from endpoint
        entity = self._endpoint_to_entity(violation.endpoint)

        # 2. Get IR constraints for entity
        ir_constraints = self._get_ir_constraints(entity, application_ir)

        # 3. AST parse generated code
        generated_constraints = self._parse_generated_constraints(
            entity, app_path
        )

        # 4. Find missing/mismatched constraints
        delta = self._compute_constraint_delta(
            ir_constraints, generated_constraints
        )

        # 5. Attribute to specific transformation stage
        root_cause = self._identify_transformation_stage(delta)

        return CausalChain(
            failing_test=violation.scenario_name,
            error_type=stack_trace.exception_class,
            ast_location=f"{delta.file}:{delta.line}",
            ir_constraint=delta.expected,
            generated_constraint=delta.actual,
            root_cause=root_cause,
            confidence=self._compute_confidence(delta)
        )
```

**Beneficio:** Mapeo causal convierte el sistema en "compiler con dataflow error analysis".

---

### 2.2 Multi-Repair Loop con Convergencia

**Objetivo:** Fixed-point iteration hasta convergencia o regresiÃ³n detectada.

```python
@dataclass
class ConvergenceResult:
    """Result of convergence analysis."""
    converged: bool
    iterations: int
    trajectory: List[float]  # pass_rate per iteration
    regression_detected: bool
    fixed_point: Optional[float]  # stable pass_rate if converged


class ConvergentRepairLoop:
    """
    Multi-repair loop with mathematical convergence detection.

    Stops when:
    1. pass_rate >= target (success)
    2. pass_rate[n] <= pass_rate[n-1] (regression)
    3. |pass_rate[n] - pass_rate[n-1]| < epsilon (convergence)
    4. n >= max_iterations (timeout)
    """

    EPSILON = 0.01  # 1% change threshold

    async def run_until_convergence(
        self,
        app_path: Path,
        target: float = 0.8,
        max_iterations: int = 3
    ) -> ConvergenceResult:
        trajectory = []

        for i in range(max_iterations):
            # Run smoke test
            result = await self.smoke_validator.run_smoke_test(app_path)
            pass_rate = result.pass_rate
            trajectory.append(pass_rate)

            # Check success
            if pass_rate >= target:
                return ConvergenceResult(
                    converged=True,
                    iterations=i + 1,
                    trajectory=trajectory,
                    regression_detected=False,
                    fixed_point=pass_rate
                )

            # Check regression
            if i > 0 and pass_rate < trajectory[i-1]:
                return ConvergenceResult(
                    converged=False,
                    iterations=i + 1,
                    trajectory=trajectory,
                    regression_detected=True,
                    fixed_point=None
                )

            # Check convergence (stuck at same level)
            if i > 0 and abs(pass_rate - trajectory[i-1]) < self.EPSILON:
                return ConvergenceResult(
                    converged=True,  # Converged but not at target
                    iterations=i + 1,
                    trajectory=trajectory,
                    regression_detected=False,
                    fixed_point=pass_rate
                )

            # Repair and continue
            await self.repair_agent.repair_from_smoke(
                result.violations, result.server_logs, app_path
            )

        return ConvergenceResult(
            converged=False,
            iterations=max_iterations,
            trajectory=trajectory,
            regression_detected=False,
            fixed_point=trajectory[-1] if trajectory else None
        )
```

**Beneficio:** Fixed-point iteration es matemÃ¡ticamente riguroso y atractivo para research.

---

### 2.3 Mutation History

**Objetivo:** Registrar secuencia completa de diffs, no solo fix final.

```python
@dataclass
class MutationRecord:
    """Single mutation in repair history."""
    iteration: int
    file_path: str
    diff: str  # unified diff format
    fix_type: str
    triggered_by: str  # violation that caused this fix
    result: str  # "success", "failure", "regression"
    timestamp: datetime


@dataclass
class MutationHistory:
    """Complete mutation history for a repair session."""
    session_id: str
    app_path: Path
    mutations: List[MutationRecord]

    def get_successful_path(self) -> List[MutationRecord]:
        """Get sequence of mutations that led to success."""
        return [m for m in self.mutations if m.result == "success"]

    def get_failed_paths(self) -> List[List[MutationRecord]]:
        """Get sequences that led to failures (for learning)."""
        # Group mutations by iteration, identify failed branches
        pass

    def rollback_to(self, iteration: int) -> None:
        """Rollback code to state at specific iteration."""
        pass


class MutationTracker:
    """
    Tracks all code mutations during repair.

    Enables:
    - Analysis of failed repair paths
    - Discovery of finer repair patterns
    - Intelligent rollback
    - Genetic Programming-like evolution
    """

    def __init__(self, app_path: Path):
        self.app_path = app_path
        self.history = MutationHistory(
            session_id=str(uuid.uuid4())[:8],
            app_path=app_path,
            mutations=[]
        )
        self._snapshots: Dict[int, Dict[str, str]] = {}

    def snapshot(self, iteration: int) -> None:
        """Take snapshot of current code state."""
        self._snapshots[iteration] = self._read_all_files()

    def record_mutation(
        self,
        iteration: int,
        file_path: str,
        old_content: str,
        new_content: str,
        fix_type: str,
        triggered_by: str
    ) -> None:
        """Record a single mutation."""
        diff = self._compute_diff(old_content, new_content)
        self.history.mutations.append(MutationRecord(
            iteration=iteration,
            file_path=file_path,
            diff=diff,
            fix_type=fix_type,
            triggered_by=triggered_by,
            result="pending",
            timestamp=datetime.now()
        ))

    def mark_iteration_result(self, iteration: int, result: str) -> None:
        """Mark all mutations in iteration with result."""
        for m in self.history.mutations:
            if m.iteration == iteration and m.result == "pending":
                m.result = result

    def rollback(self, to_iteration: int) -> None:
        """Rollback to snapshot at iteration."""
        if to_iteration in self._snapshots:
            self._restore_files(self._snapshots[to_iteration])
```

**Beneficio:** Convierte repair engine en "Genetic Programming dirigido".

---

### 2.4 Confidence Model para Repair

**Objetivo:** Ordenar estrategias de repair por probabilidad de Ã©xito.

```python
@dataclass
class RepairCandidate:
    """A candidate repair with confidence score."""
    strategy: RepairStrategy
    target_file: str
    fix_description: str
    confidence: float  # 0.0 - 1.0

    # Components of confidence score
    pattern_score: float      # Historical success rate of this pattern
    ir_context_score: float   # How well IR matches the error
    semantic_match_score: float  # Semantic similarity to known fixes


class ConfidenceModel:
    """
    Computes confidence scores for repair candidates.

    confidence = Î± * pattern_score + Î² * ir_context_score + Î³ * semantic_match

    Where:
    - pattern_score: Success rate from Neo4j FixPattern history
    - ir_context_score: How well IR explains the failure
    - semantic_match_score: Embedding similarity to successful fixes
    """

    ALPHA = 0.4  # Weight for historical pattern success
    BETA = 0.35  # Weight for IR context match
    GAMMA = 0.25  # Weight for semantic similarity

    def __init__(self, pattern_store: FixPatternStore, embedder: SentenceTransformer):
        self.pattern_store = pattern_store
        self.embedder = embedder

    def score_candidates(
        self,
        candidates: List[RepairCandidate],
        violation: SmokeViolation,
        causal_chain: CausalChain
    ) -> List[RepairCandidate]:
        """Score and rank repair candidates by confidence."""

        for candidate in candidates:
            # 1. Pattern score from history
            pattern = self.pattern_store.get_pattern(
                candidate.strategy.name,
                violation.endpoint_pattern
            )
            candidate.pattern_score = pattern.success_rate if pattern else 0.5

            # 2. IR context score
            candidate.ir_context_score = self._compute_ir_context_score(
                candidate, causal_chain
            )

            # 3. Semantic match score
            candidate.semantic_match_score = self._compute_semantic_match(
                candidate.fix_description,
                causal_chain.root_cause
            )

            # Combined confidence
            candidate.confidence = (
                self.ALPHA * candidate.pattern_score +
                self.BETA * candidate.ir_context_score +
                self.GAMMA * candidate.semantic_match_score
            )

        # Sort by confidence descending
        return sorted(candidates, key=lambda c: c.confidence, reverse=True)

    def _compute_ir_context_score(
        self,
        candidate: RepairCandidate,
        causal_chain: CausalChain
    ) -> float:
        """How well does the repair strategy address the IR gap?"""
        # Match strategy type to causal chain root cause
        strategy_matches = {
            "add_nullable": ["constraint missing", "required field"],
            "fix_foreign_key": ["relationship", "foreign key"],
            "add_validator": ["validation", "format", "range"],
        }

        root_cause_lower = causal_chain.root_cause.lower()
        strategy_keywords = strategy_matches.get(candidate.strategy.name, [])

        return 1.0 if any(kw in root_cause_lower for kw in strategy_keywords) else 0.3
```

**Beneficio:** Da apariencia de "machine intelligence" ordenando por probabilidad.

---

### 2.5 Delta IR Validation

**Objetivo:** Solo validar entidades/endpoints afectados por el repair (70% reducciÃ³n de tiempo).

```python
@dataclass
class AffectedScope:
    """Scope of code affected by a repair."""
    entities: Set[str]
    endpoints: Set[str]
    constraints: Set[str]
    test_files: Set[str]


class DeltaIRValidator:
    """
    Validates only the subset of IR affected by repairs.

    Instead of full smoke test (75 scenarios), runs only:
    - Tests for affected entities
    - Tests for affected endpoints
    - Related constraint validations

    Reduces validation time ~70%.
    """

    def compute_affected_scope(
        self,
        mutations: List[MutationRecord],
        application_ir: ApplicationIR
    ) -> AffectedScope:
        """Determine what IR elements are affected by mutations."""

        affected_entities = set()
        affected_endpoints = set()
        affected_constraints = set()

        for mutation in mutations:
            # Parse file to identify affected elements
            if "models/entities.py" in mutation.file_path:
                entities = self._extract_entities_from_diff(mutation.diff)
                affected_entities.update(entities)

            elif "models/schemas.py" in mutation.file_path:
                entities = self._extract_schemas_from_diff(mutation.diff)
                affected_entities.update(entities)

            elif "api/routes" in mutation.file_path:
                endpoints = self._extract_endpoints_from_diff(mutation.diff)
                affected_endpoints.update(endpoints)

        # Expand to related constraints
        for entity in affected_entities:
            constraints = self._get_entity_constraints(entity, application_ir)
            affected_constraints.update(constraints)

        # Map to test files
        test_files = self._map_to_test_files(
            affected_entities, affected_endpoints
        )

        return AffectedScope(
            entities=affected_entities,
            endpoints=affected_endpoints,
            constraints=affected_constraints,
            test_files=test_files
        )

    async def validate_delta(
        self,
        scope: AffectedScope,
        app_path: Path
    ) -> DeltaValidationResult:
        """Run validation only on affected scope."""

        # 1. Run only affected smoke scenarios
        affected_scenarios = self._filter_scenarios(scope.endpoints)
        smoke_result = await self.smoke_validator.run_scenarios(
            affected_scenarios, app_path
        )

        # 2. Run only affected tests
        test_result = await self._run_affected_tests(scope.test_files, app_path)

        # 3. Validate only affected constraints
        constraint_result = self._validate_constraints(
            scope.constraints, scope.entities, app_path
        )

        return DeltaValidationResult(
            scope=scope,
            smoke_result=smoke_result,
            test_result=test_result,
            constraint_result=constraint_result,
            full_validation_skipped=True,
            time_saved_percent=self._compute_time_savings(scope)
        )
```

**Beneficio:** Escala real para Anthropic - no re-validar todo cada iteraciÃ³n.

---

## Updated Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COGNITIVE SOFTWARE ENGINE ARCHITECTURE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Smoke Test  â”‚â”€â”€â”€â–¶â”‚   Causal     â”‚â”€â”€â”€â–¶â”‚  Confidence   â”‚â”€â”€â”€â–¶â”‚   Repair     â”‚  â”‚
â”‚  â”‚ + Logs      â”‚    â”‚ Attribution  â”‚    â”‚    Model      â”‚    â”‚  Strategy    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                   â”‚                    â”‚          â”‚
â”‚         â”‚                  â–¼                   â–¼                    â–¼          â”‚
â”‚         â”‚          IR â†” AST â†” Test      Ranked Repairs       Apply Fix        â”‚
â”‚         â”‚             Mapping            by Probability       + Record        â”‚
â”‚         â”‚                                                         â”‚          â”‚
â”‚         â”‚                                                         â–¼          â”‚
â”‚         â”‚                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚         â”‚                                               â”‚ Mutation Historyâ”‚  â”‚
â”‚         â”‚                                               â”‚ diff_1 â†’ diff_2 â”‚  â”‚
â”‚         â”‚                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                         â”‚          â”‚
â”‚         â–¼                                                         â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    CONVERGENT REPAIR LOOP                                â”‚  â”‚
â”‚  â”‚                                                                          â”‚  â”‚
â”‚  â”‚  Iteration 1 â”€â”€â–¶ Iteration 2 â”€â”€â–¶ Iteration 3                            â”‚  â”‚
â”‚  â”‚     56%            72%             85% âœ…                                 â”‚  â”‚
â”‚  â”‚                                                                          â”‚  â”‚
â”‚  â”‚  Stop conditions:                                                        â”‚  â”‚
â”‚  â”‚  âœ… pass_rate >= 80% (success)                                           â”‚  â”‚
â”‚  â”‚  âš ï¸ regression detected (rollback)                                       â”‚  â”‚
â”‚  â”‚  ğŸ“Š converged at fixed point                                             â”‚  â”‚
â”‚  â”‚  â±ï¸ max_iterations reached                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                                     â”‚
â”‚         â–¼                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    DELTA IR VALIDATION                                   â”‚  â”‚
â”‚  â”‚                                                                          â”‚  â”‚
â”‚  â”‚  Full validation: 75 scenarios Ã— 3 iterations = 225 runs                â”‚  â”‚
â”‚  â”‚  Delta validation: 15 scenarios Ã— 3 iterations = 45 runs  (70% faster)  â”‚  â”‚
â”‚  â”‚                                                                          â”‚  â”‚
â”‚  â”‚  Only validate:                                                          â”‚  â”‚
â”‚  â”‚  â€¢ Affected entities (from mutation diff)                               â”‚  â”‚
â”‚  â”‚  â€¢ Affected endpoints (from route changes)                              â”‚  â”‚
â”‚  â”‚  â€¢ Related constraints (from IR graph)                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                                     â”‚
â”‚         â–¼                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    LEARNING SYSTEM                                       â”‚  â”‚
â”‚  â”‚                                                                          â”‚  â”‚
â”‚  â”‚  â€¢ Successful mutation paths â†’ FixPatterns promoted                     â”‚  â”‚
â”‚  â”‚  â€¢ Failed mutation paths â†’ Anti-patterns demoted                        â”‚  â”‚
â”‚  â”‚  â€¢ Causal chains â†’ IR transformation improvements                       â”‚  â”‚
â”‚  â”‚  â€¢ Confidence model â†’ Self-improving repair ranking                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Progreso de ImplementaciÃ³n

### Phase 1: Core Smoke-Repair (Tasks 1-5) - âœ… COMPLETADO

| Task | Estado | Archivo |
|------|--------|---------|
| 1. Implementar SmokeRepairOrchestrator | âœ… | `src/validation/smoke_repair_orchestrator.py` |
| 2. Agregar server log capture | âœ… | `src/validation/runtime_smoke_validator.py` |
| 3. Implementar repair strategies | âœ… | `smoke_repair_orchestrator.py` (DatabaseRepairStrategy, ValidationRepairStrategy, etc.) |
| 4. Integrar en pipeline | âœ… | `tests/e2e/real_e2e_full_pipeline.py` (`_attempt_runtime_repair`) |
| 5. Agregar fix pattern learning | âœ… | `src/validation/smoke_test_pattern_adapter.py` (FixPatternLearner) |

**Componentes implementados:**
- `SmokeRepairOrchestrator` - Ciclo smokeâ†’repairâ†’retest con convergencia y regresiÃ³n
- `SmokeRepairConfig` - ConfiguraciÃ³n (max_iterations, target_pass_rate, epsilon)
- `ServerLogParser` - Parsing de logs Docker y stack traces
- `ErrorClassifier` - ClasificaciÃ³n de errores (DATABASE, VALIDATION, IMPORT, etc.)
- `MutationTracker` - Tracking de cambios de cÃ³digo
- `repair_from_smoke` en CodeRepairAgent - MÃ©todo de repair basado en smoke failures
- `FixPattern` - Dataclass para patrones de fix aprendidos
- `FixPatternLearner` - Learning de fix patterns con Neo4j persistence
- `get_fix_pattern_learner` - Singleton para acceder al learner

**IntegraciÃ³n pipeline:**
- `_attempt_runtime_repair` ahora usa `SmokeRepairOrchestrator` cuando disponible
- Fallback a legacy repair loop si orquestador no disponible
- Server logs pasados a `repair_from_smoke` para anÃ¡lisis de root cause

### Phase 2: Cognitive Enhancements (Tasks 6-10) - âœ… COMPLETADO

| Task | Estado | Archivo |
|------|--------|---------|
| 6. Causal Repair Attribution | âœ… | `src/validation/repair_confidence_model.py` (LightweightCausalAttributor) |
| 7. Convergence Detection | âœ… | `src/validation/smoke_repair_orchestrator.py` |
| 8. Mutation History | âœ… | `src/validation/smoke_repair_orchestrator.py` (MutationTracker) |
| 9. Confidence Model | âœ… | `src/validation/repair_confidence_model.py` (RepairConfidenceModel) |
| 10. Delta IR Validation | âœ… | `src/validation/delta_ir_validator.py` (DeltaIRValidator) |

**Nuevos componentes Phase 2:**
- `DeltaIRValidator` - Valida solo entidades/endpoints afectados (70% faster)
- `AffectedScope` - Scope de cÃ³digo afectado por mutations
- `DeltaValidationIntegration` - IntegraciÃ³n con SmokeRepairOrchestrator
- `RepairConfidenceModel` - Ranking de repairs por probabilidad de Ã©xito
- `RepairCandidate` - Candidato de repair con confidence score
- `LightweightCausalAttributor` - AtribuciÃ³n causal error â†’ IR root cause
- `CausalChain` - Cadena causal desde test failure hasta root cause

### Phase 3: E2E Pipeline Integration - âœ… COMPLETADO

| Component | Integration Point | Status |
|-----------|------------------|--------|
| SmokeRepairOrchestrator | `tests/e2e/real_e2e_full_pipeline.py:_attempt_runtime_repair` | âœ… |
| DeltaIRValidator | Integrated in SmokeRepairOrchestrator.__init__ | âœ… |
| RepairConfidenceModel | `_repair_from_smoke()` â†’ `_apply_repair_with_confidence()` | âœ… |
| LightweightCausalAttributor | Integrated in repair loop for root cause analysis | âœ… |
| FixPatternLearner | `_record_learning()` + `_try_known_fix()` | âœ… |

**E2E Integration Details:**
- All Phase 2 components auto-enable if available
- Graceful degradation if components missing (ImportError handling)
- Metrics collector tracks Phase 2 component availability
- Progress logging shows component activation status

**New E2E Flags:**
- `DELTA_VALIDATOR_AVAILABLE` - 70% validation speedup
- `REPAIR_CONFIDENCE_MODEL_AVAILABLE` - Probabilistic repair ranking
- `FIX_PATTERN_LEARNER_AVAILABLE` - Cross-session learning

### Estimated Impact

| Feature | Effort | Impact |
|---------|--------|--------|
| Causal Attribution | 4h | Compiler-level error analysis |
| Convergence Loop | 2h | Mathematical rigor |
| Mutation History | 3h | Genetic Programming capabilities |
| Confidence Model | 4h | ML-like repair ordering |
| Delta Validation | 3h | 70% speed improvement |
| E2E Integration | 2h | Full pipeline activation |

---

## Critical Integration Points (User Requirements)

### 1. IR Realignment After Repairs

**Requisito:** "recorda q se tiene q alimentar y realinear con IR"

DespuÃ©s de cada repair, el sistema DEBE realinear con IR para mantener consistencia:

```python
class IRCodeCorrelator:
    """
    Realinea IR despuÃ©s de reparaciones de cÃ³digo.

    UbicaciÃ³n: src/cognitive/services/ir_code_correlator.py
    """

    async def realign_after_repair(
        self,
        fixes: List[CodeFix],
        application_ir: ApplicationIR,
    ) -> IRRealignmentResult:
        """
        Flujo:
        1. Parse quÃ© cambiÃ³ en cada fix
        2. Identificar elementos IR afectados
        3. Actualizar IR constraints/fields si cambiÃ³ el cÃ³digo
        4. Persistir IR actualizado
        5. Registrar delta para learning
        """
        realignments = []

        for fix in fixes:
            # 1. Analizar cambios
            changes = self._analyze_fix_changes(fix)

            # 2. Encontrar elementos IR afectados
            affected = self._find_affected_ir_elements(changes, application_ir)

            # 3. Aplicar realignment
            for element in affected:
                if element.type == "entity_field":
                    # Fix cambiÃ³ nullable? Actualizar IR
                    if "nullable" in changes.keywords:
                        element.ir_node.nullable = True

                elif element.type == "endpoint":
                    # Fix cambiÃ³ response schema? Actualizar IR
                    if "response" in changes.keywords:
                        element.ir_node.response_schema = changes.new_schema

                realignments.append(IRRealignment(
                    element=element,
                    before=element.original_state,
                    after=element.new_state,
                ))

        # 4. Persistir IR actualizado
        await self._persist_ir(application_ir)

        # 5. Registrar para learning
        self._record_ir_delta(realignments)

        return IRRealignmentResult(
            realignments=realignments,
            ir_version=application_ir.version + 1,
        )
```

**Flujo de datos IR Realignment:**
```
Smoke Error â†’ Repair Code â†’ IR Correlator â†’ Update IR â†’ Persist
      â†“              â†“              â†“              â†“
  violations     code fixes    find deltas   new IR version
                                    â†“
                          Learning System (record deltas)
```

### 2. Integration con NegativePatternStore (Learned Anti-Patterns)

**Requisito:** "y de lo aprendido"

El repair loop DEBE consultar anti-patterns aprendidos para:
1. Aplicar fixes conocidos primero (alta confianza)
2. Evitar reparaciones que fallaron antes
3. Mejorar prompts de repair con context histÃ³rico

```python
class SmokeRepairOrchestrator:
    """
    IntegraciÃ³n con NegativePatternStore en el repair loop.
    """

    async def _repair_with_learned_patterns(
        self,
        violation: SmokeViolation,
        stack_trace: str,
        app_path: Path,
    ) -> Optional[CodeFix]:
        """
        Orden de prioridad para repair:
        1. Anti-pattern conocido con fix (NegativePatternStore)
        2. Fix pattern histÃ³rico exitoso (FixPatternLearner)
        3. LLM-based repair (fallback)
        """

        # 1. Consultar NegativePatternStore (Generation Feedback Loop)
        from src.learning import get_negative_pattern_store
        pattern_store = get_negative_pattern_store()

        # Buscar anti-pattern que matchee este error
        anti_pattern = pattern_store.get_patterns_for_error(
            error_type=violation.error_type,
            entity=self._extract_entity(violation.endpoint),
        )

        if anti_pattern and anti_pattern.correct_code_snippet:
            logger.info(
                f"ğŸ“š Using learned anti-pattern: {anti_pattern.pattern_id} "
                f"(seen {anti_pattern.occurrence_count}x)"
            )

            # Aplicar fix conocido
            fix = await self._apply_known_fix(
                violation=violation,
                fix_template=anti_pattern.correct_code_snippet,
                app_path=app_path,
            )

            if fix:
                # Incrementar prevention count
                pattern_store.increment_prevention(anti_pattern.pattern_id)
                return fix

        # 2. Consultar FixPatternLearner (Smoke Repair Learning)
        from src.validation.smoke_test_pattern_adapter import get_fix_pattern_learner
        fix_learner = get_fix_pattern_learner()

        known_fix = fix_learner.get_known_fix(
            error_type=violation.error_type,
            endpoint_pattern=violation.endpoint,
            exception_class=self._extract_exception(stack_trace),
        )

        if known_fix and known_fix.success_rate >= 0.7:
            logger.info(
                f"ğŸ¯ Using historical fix pattern: {known_fix.pattern_id} "
                f"(success rate: {known_fix.success_rate:.0%})"
            )
            return await self._apply_fix_template(known_fix.fix_template, app_path)

        # 3. Fallback: LLM repair con context enriquecido
        logger.info("ğŸ¤– Using LLM repair with learned context")
        return await self._llm_repair_with_context(
            violation=violation,
            stack_trace=stack_trace,
            anti_patterns=[anti_pattern] if anti_pattern else [],
            app_path=app_path,
        )
```

### 3. Docker Rebuild sin Cache

**Requisito:** "volver a levantar docker sin cache y otra vez smoke"

DespuÃ©s de cada repair iteration, rebuild forzado:

```python
async def _rebuild_docker_no_cache(self, app_path: Path) -> None:
    """
    Reconstruye Docker sin cache para asegurar que los cambios se apliquen.

    IMPORTANTE: --no-cache es crÃ­tico porque:
    1. El cÃ³digo fue modificado durante repair
    2. Docker puede tener layers cacheadas con cÃ³digo viejo
    3. Sin --no-cache, los cambios NO se verÃ­an
    """
    compose_file = app_path / "docker-compose.yml"

    logger.info("ğŸ”„ Rebuilding Docker (--no-cache)...")

    # 1. Down containers
    await run_command(
        f"docker-compose -f {compose_file} down -v",  # -v para volumes tambiÃ©n
        cwd=app_path,
        timeout=60,
    )

    # 2. Build sin cache
    await run_command(
        f"docker-compose -f {compose_file} build --no-cache",
        cwd=app_path,
        timeout=300,  # 5 min para build completo
    )

    # 3. Up fresh
    await run_command(
        f"docker-compose -f {compose_file} up -d",
        cwd=app_path,
        timeout=120,
    )

    # 4. Wait healthy
    await self._wait_for_healthy(app_path, timeout=60, retries=10)

    logger.info("âœ… Docker rebuilt and healthy")
```

### Complete Repair Loop con Todas las Integraciones

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLETE SMOKE-DRIVEN REPAIR LOOP                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  ITERATION N:                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                                          â”‚    â”‚
â”‚  â”‚  1. SMOKE TEST                                                           â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ Run all scenarios                                                â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ Capture server logs                                              â”‚    â”‚
â”‚  â”‚     â””â”€â”€ Parse stack traces                                               â”‚    â”‚
â”‚  â”‚              â”‚                                                           â”‚    â”‚
â”‚  â”‚              â–¼                                                           â”‚    â”‚
â”‚  â”‚  2. COLLECT FEEDBACK (Learning)                                         â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ SmokeFeedbackClassifier.classify_for_generation()               â”‚    â”‚
â”‚  â”‚     â””â”€â”€ NegativePatternStore.store(anti_pattern)                        â”‚    â”‚
â”‚  â”‚              â”‚                                                           â”‚    â”‚
â”‚  â”‚              â–¼                                                           â”‚    â”‚
â”‚  â”‚  3. REPAIR WITH LEARNED PATTERNS                                        â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ Query NegativePatternStore (anti-patterns)  â—€â”€â”€ "de lo aprendido" â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ Query FixPatternLearner (historical fixes)                      â”‚    â”‚
â”‚  â”‚     â””â”€â”€ LLM repair with enriched context (fallback)                     â”‚    â”‚
â”‚  â”‚              â”‚                                                           â”‚    â”‚
â”‚  â”‚              â–¼                                                           â”‚    â”‚
â”‚  â”‚  4. IR REALIGNMENT                              â—€â”€â”€ "realinear con IR"  â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ IRCodeCorrelator.realign_after_repair()                         â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ Update IR constraints if code changed                           â”‚    â”‚
â”‚  â”‚     â””â”€â”€ Persist updated IR                                              â”‚    â”‚
â”‚  â”‚              â”‚                                                           â”‚    â”‚
â”‚  â”‚              â–¼                                                           â”‚    â”‚
â”‚  â”‚  5. DOCKER REBUILD (--no-cache)                â—€â”€â”€ "sin cache"          â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ docker-compose down -v                                          â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ docker-compose build --no-cache                                 â”‚    â”‚
â”‚  â”‚     â””â”€â”€ docker-compose up -d + wait healthy                             â”‚    â”‚
â”‚  â”‚              â”‚                                                           â”‚    â”‚
â”‚  â”‚              â–¼                                                           â”‚    â”‚
â”‚  â”‚  6. CONVERGENCE CHECK                                                    â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ pass_rate >= 80%? â†’ SUCCESS                                     â”‚    â”‚
â”‚  â”‚     â”œâ”€â”€ regression? â†’ ROLLBACK                                          â”‚    â”‚
â”‚  â”‚     â””â”€â”€ max_iterations? â†’ STOP                                          â”‚    â”‚
â”‚  â”‚                                                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                                                       â”‚
â”‚                          â–¼                                                       â”‚
â”‚  LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LEARNING FEEDBACK:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Smoke Results â†’ FeedbackCollector â†’ NegativePatternStore â”€â”€â”                   â”‚
â”‚                                                              â”‚                   â”‚
â”‚  Repair Results â†’ FixPatternLearner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚                                                              â”‚                   â”‚
â”‚  IR Changes â†’ IRCodeCorrelator.record_delta() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚                                                              â–¼                   â”‚
â”‚                                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                                             â”‚  NEXT GENERATION    â”‚             â”‚
â”‚                                             â”‚  IMPROVEMENT        â”‚             â”‚
â”‚                                             â”‚                     â”‚             â”‚
â”‚                                             â”‚  - CodeGen uses     â”‚             â”‚
â”‚                                             â”‚    anti-patterns    â”‚             â”‚
â”‚                                             â”‚  - Repair uses      â”‚             â”‚
â”‚                                             â”‚    fix patterns     â”‚             â”‚
â”‚                                             â”‚  - IR stays         â”‚             â”‚
â”‚                                             â”‚    consistent       â”‚             â”‚
â”‚                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Archivos a Modificar/Crear

| Archivo | AcciÃ³n | Cambios | Estado |
|---------|--------|---------|--------|
| `src/validation/smoke_repair_orchestrator.py` | MODIFICAR | Agregar `_repair_with_learned_patterns()`, `_rebuild_docker_no_cache()`, `run_full_repair_cycle()` | âœ… COMPLETADO |
| `src/cognitive/services/ir_code_correlator.py` | MODIFICAR | Agregar `realign_after_repair()` | âœ… COMPLETADO |
| `tests/e2e/real_e2e_full_pipeline.py` | MODIFICAR | Integrar IR realignment y usar `run_full_repair_cycle()` | âœ… COMPLETADO |

---

## Implementation Session Log - 2025-11-30

### Nuevos MÃ©todos Implementados

#### smoke_repair_orchestrator.py

1. **`_get_learned_antipatterns()`**
   - Query NegativePatternStore para anti-patterns relevantes
   - Busca por: entidad, endpoint, exception class
   - Deduplica por pattern_id
   - Returns: List[Dict] con patterns y su metadata

2. **`_repair_with_learned_patterns()`**
   - Usa anti-patterns como guÃ­a de repair
   - Ordena por confidence Ã— occurrences
   - Aplica correct_pattern si wrong_pattern matchea
   - Incrementa prevention_count en Ã©xito

3. **`_rebuild_docker_no_cache()`**
   - Stop â†’ Remove â†’ Build --no-cache
   - Timeout 5 min para build
   - Graceful degradation si Docker no disponible

4. **`_restart_container()`**
   - Run con port mapping
   - Wait 3s para startup
   - Returns bool para control flow

5. **`run_full_repair_cycle()`**
   - Ciclo completo: Smoke â†’ Learned Patterns â†’ Repair â†’ Docker Rebuild â†’ Loop
   - Soporta `with_docker_rebuild` flag
   - Tracking de `learned_patterns_applied`
   - IntegraciÃ³n de todos los Phase 2 components

#### ir_code_correlator.py

6. **`realign_after_repair()`**
   - Actualiza ApplicationIR despuÃ©s de repairs
   - Calcula pass_rate delta
   - Infiere entities/endpoints afectados
   - Persiste IRRealignment a Neo4j

7. **`_infer_entity_from_repair()`**
   - Extrae entity name de repair description
   - Patterns: "to X_id", "Made X_"
   - Fallback: basename de file path

8. **`_update_entity_metadata()`** / **`_update_endpoint_metadata()`**
   - Agrega _repair_history a IR elements
   - Tracking de fix_type, description, timestamp

### E2E Pipeline Integration

- Import de `IRCodeCorrelator`, `get_ir_code_correlator`
- Flag `IR_CODE_CORRELATOR_AVAILABLE`
- Usa `run_full_repair_cycle()` con `with_docker_rebuild=False` (E2E mode)
- Post-repair: `realign_after_repair()` para sync IR
- MÃ©tricas adicionales: `phase2_ir_correlator`, `CP-8.5.IR_REALIGN`

### VerificaciÃ³n

```bash
# Imports OK
PYTHONPATH=/home/kwar/code/agentic-ai python3 -c "
from src.validation.smoke_repair_orchestrator import SmokeRepairOrchestrator
from src.cognitive.services.ir_code_correlator import get_ir_code_correlator
print('âœ… All imports OK')
"
```

---

## Bug #157: CodeRepairAgent Integration in Generic Error Repair

**Fecha:** 2025-11-30
**Estado:** Implementado

### Problema

El mÃ©todo `_fix_generic_error` era un stub que siempre retornaba `success=False` sin intentar reparar nada:

```python
# ANTES (stub inÃºtil):
async def _fix_generic_error(...) -> Optional[RepairFix]:
    return RepairFix(
        file_path=trace.file_path if trace else "",
        fix_type="generic",
        description=f"Generic error on {violation.endpoint}: {violation.error_type}",
        success=False  # â† Nunca reparaba!
    )
```

Esto causaba que todos los errores que no matcheaban patrones especÃ­ficos (DATABASE, VALIDATION, etc.) nunca fueran reparados, resultando en `Total repairs: 0` a pesar de tener violaciones.

### SoluciÃ³n ArquitectÃ³nica

Integrar `CodeRepairAgent.repair_from_smoke()` como fallback LLM-powered para errores genÃ©ricos:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REPAIR STRATEGY HIERARCHY (Updated)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Violation                                                                   â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â”œâ”€â†’ DATABASE pattern? â”€â”€â”€â†’ DatabaseRepairStrategy                      â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â”œâ”€â†’ VALIDATION pattern? â”€â”€â†’ ValidationRepairStrategy                   â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â”œâ”€â†’ SERVICE pattern? â”€â”€â”€â”€â”€â†’ ServiceRepairStrategy                      â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â”œâ”€â†’ IMPORT pattern? â”€â”€â”€â”€â”€â”€â†’ ImportRepairStrategy                       â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â””â”€â†’ No pattern match â”€â”€â”€â”€â”€â†’ _fix_generic_error() â”€â”€â”€â”€â”€â”               â”‚
â”‚                                                              â”‚               â”‚
â”‚                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                      â–¼                                       â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                           â”‚   CodeRepairAgent       â”‚  â† NEW (Bug #157)     â”‚
â”‚                           â”‚   repair_from_smoke()   â”‚                       â”‚
â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚                           â”‚ 1. Group violations     â”‚                       â”‚
â”‚                           â”‚ 2. LLM analyzes stack   â”‚                       â”‚
â”‚                           â”‚ 3. Generate targeted    â”‚                       â”‚
â”‚                           â”‚    code patches         â”‚                       â”‚
â”‚                           â”‚ 4. Apply fixes          â”‚                       â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                      â”‚                                       â”‚
â”‚                                      â–¼                                       â”‚
â”‚                           success=True if fixed                             â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cambios de CÃ³digo

**Archivo:** `src/validation/smoke_repair_orchestrator.py`

1. **Import CodeRepairAgent:**
```python
# Bug #157: CodeRepairAgent for LLM-powered generic error repair
try:
    from src.mge.v2.agents.code_repair_agent import CodeRepairAgent
    CODE_REPAIR_AGENT_AVAILABLE = True
except ImportError:
    CODE_REPAIR_AGENT_AVAILABLE = False
    CodeRepairAgent = None
```

2. **Instance Attributes:**
```python
def __init__(self, ...):
    # Bug #157: Server logs storage for CodeRepairAgent integration
    self._current_server_logs: str = ""
    self._current_app_path: Optional[Path] = None
    self.code_repair_agent: Optional[CodeRepairAgent] = None
```

3. **Server Logs Storage (en ambos repair cycles):**
```python
# Bug #157: Store server_logs for CodeRepairAgent integration
if hasattr(smoke_result, 'server_logs') and smoke_result.server_logs:
    self._current_server_logs = smoke_result.server_logs
    self._current_app_path = app_path
```

4. **`_fix_generic_error` con CodeRepairAgent:**
```python
async def _fix_generic_error(
    self,
    violation: SmokeViolation,
    trace: Optional[StackTrace],
    app_path: Path,
    application_ir
) -> Optional[RepairFix]:
    """
    Fallback: delegate to CodeRepairAgent for LLM-powered repair.
    """
    # Bug #157: Use CodeRepairAgent for LLM-powered repair
    if CODE_REPAIR_AGENT_AVAILABLE and self._current_server_logs:
        try:
            # Create or reuse CodeRepairAgent
            if not self.code_repair_agent:
                self.code_repair_agent = CodeRepairAgent(
                    output_path=app_path,
                    application_ir=application_ir
                )

            # Prepare violation for repair_from_smoke
            violation_dict = {
                'endpoint': violation.endpoint,
                'error_type': violation.error_type,
                'status_code': violation.actual_status,
                'expected_status': violation.expected_status,
                'file': trace.file_path if trace else '',
                'stack_trace': trace.full_trace if trace else ''
            }

            logger.info(f"    ğŸ¤– CodeRepairAgent: Attempting LLM-powered repair for {violation.endpoint}")

            # Call repair_from_smoke
            repair_result = await self.code_repair_agent.repair_from_smoke(
                violations=[violation_dict],
                server_logs=self._current_server_logs,
                app_path=app_path,
                stack_traces=[{'trace': trace.full_trace, 'file': trace.file_path}] if trace else None
            )

            if repair_result.success and repair_result.repairs_applied:
                logger.info(f"    âœ… CodeRepairAgent: Fixed {len(repair_result.repairs_applied)} issues")
                return RepairFix(
                    file_path=repair_result.repaired_files[0] if repair_result.repaired_files else "",
                    fix_type="llm_repair",
                    description=f"LLM-powered repair: {', '.join(repair_result.repairs_applied[:3])}",
                    success=True
                )
            else:
                logger.debug(f"CodeRepairAgent could not fix: {repair_result.error_message}")

        except Exception as e:
            logger.warning(f"CodeRepairAgent failed: {e}")

    # Fallback if CodeRepairAgent not available or failed
    return RepairFix(
        file_path=trace.file_path if trace else "",
        fix_type="generic",
        description=f"Generic error on {violation.endpoint}: {violation.error_type}",
        success=False
    )
```

### Impacto

| MÃ©trica | Antes | DespuÃ©s |
|---------|-------|---------|
| Generic errors repaired | 0 | >0 (depends on LLM) |
| Repair coverage | ~60% (only pattern-matched) | ~95% (all violations get attempt) |
| `Total repairs: 0` bug | Yes | Fixed |

### Dependencias

- `CodeRepairAgent.repair_from_smoke()` debe existir y funcionar
- `server_logs` debe estar capturado (Bug #156)
- Import graceful con try/except para degradaciÃ³n elegante

### VerificaciÃ³n

```bash
# E2E Run #062 deberÃ­a mostrar:
# 1. "ğŸ¤– CodeRepairAgent: Attempting LLM-powered repair for ..."
# 2. "âœ… CodeRepairAgent: Fixed X issues"
# 3. Total repairs > 0

grep -E "(CodeRepairAgent|Total repairs)" /home/kwar/code/agentic-ai/logs/runs/test_devmatrix_000_062.log
```

---

**Documento creado:** 2025-11-29
**Ãšltima actualizaciÃ³n:** 2025-11-30 (Bug #157 - CodeRepairAgent Integration)
**Autor:** DevMatrix Pipeline Team
