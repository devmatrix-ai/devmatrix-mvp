# ğŸ§  Sistema de Learning - Arquitectura Completa

**Autor:** AnÃ¡lisis Ultrathink del Pipeline E2E
**Fecha:** 2025-11-28
**VersiÃ³n:** 1.1 - Actualizado con Learning Gaps Sprint 8
**Ãšltima actualizaciÃ³n:** 2025-11-29

---

## ğŸ†• Nuevos Componentes (Sprint 8 - Learning Gaps)

```
src/cognitive/services/
â”œâ”€ error_knowledge_repository.py   â† Gap 1: Active Learning
â”œâ”€ pattern_mining_service.py       â† Gap 3: Pattern Mining from Neo4j
â””â”€ ir_code_correlator.py          â† Gap 5: IR-to-Code Correlation

src/classification/
â””â”€ requirements_classifier_trainer.py  â† Gap 2: Classifier Learning

src/services/
â”œâ”€ error_pattern_store.py          â† Gap 4: FixPattern methods
â””â”€ spec_complexity_analyzer.py     â† Gap 6: Spec Complexity Learning

src/validation/
â”œâ”€ constraint_learning_service.py  â† Gap 7: Constraint Violations
â””â”€ smoke_test_pattern_adapter.py   â† SmokeTestâ†’Pattern feedback

scripts/migrations/neo4j/
â”œâ”€ 011_error_knowledge_schema.cypher
â””â”€ 012_fix_pattern_schema.cypher
```

**Ver:** [LEARNING_GAPS_IMPLEMENTATION_PLAN.md](./LEARNING_GAPS_IMPLEMENTATION_PLAN.md) para detalles.

---

## ğŸ“Š Arquitectura General del Sistema de Learning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CICLO DE LEARNING COMPLETO                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. CAPTURA DE PATRONES
   â”œâ”€ CodeGenerationService genera cÃ³digo
   â”œâ”€ Se ejecutan tests y validaciones
   â””â”€ Se registra el resultado (Ã©xito/error)

2. ALMACENAMIENTO DUAL
   â”œâ”€ Neo4j: Estructura y relaciones
   â””â”€ Qdrant: Embeddings semÃ¡nticos (768-dim GraphCodeBERT)

3. ANÃLISIS Y SCORING
   â”œâ”€ PatternAnalyzer: reusabilidad, seguridad, calidad
   â”œâ”€ QualityEvaluator: mÃ©tricas de ejecuciÃ³n y validaciÃ³n
   â””â”€ DualValidator: validaciÃ³n con LLMs (Claude + GPT-4)

4. PROMOCIÃ“N DE PATRONES
   â”œâ”€ LLM stratum â†’ AST stratum â†’ TEMPLATE stratum
   â”œâ”€ Criterios formales por dominio
   â””â”€ Sistema adaptativo de thresholds

5. REUTILIZACIÃ“N
   â”œâ”€ BÃºsqueda semÃ¡ntica en PatternBank
   â”œâ”€ Ranking basado en ejecuciones (DAG)
   â””â”€ Fallback keywords cuando no hay matches
```

---

## ğŸ—ºï¸ Mapa de Componentes del Sistema

### Archivos Principales

```
src/cognitive/patterns/
â”œâ”€ pattern_feedback_integration.py  â† Orquestador principal
â”œâ”€ pattern_bank.py                  â† Almacenamiento de patterns promovidos
â”œâ”€ pattern_classifier.py            â† ClasificaciÃ³n semÃ¡ntica
â”œâ”€ pattern_analyzer.py              â† AnÃ¡lisis de calidad de cÃ³digo
â””â”€ dual_validator.py                â† ValidaciÃ³n con 2 LLMs

src/services/
â”œâ”€ error_pattern_store.py           â† Almacenamiento errores/Ã©xitos
â”œâ”€ pattern_promoter.py              â† Sistema de stratum promotion
â””â”€ code_generation_service.py       â† GeneraciÃ³n + pattern reuse

tests/e2e/
â””â”€ real_e2e_full_pipeline.py        â† Pipeline completo con learning
```

### Puntos de Learning en el Pipeline E2E

```python
real_e2e_full_pipeline.py:
â”œâ”€ Line 1254: _initialize_services()
â”‚  â”œâ”€ 1269: self.pattern_bank = PatternBank()
â”‚  â”œâ”€ 1344: self.error_pattern_store = ErrorPatternStore()  # â† Guarda errores/Ã©xitos
â”‚  â””â”€ 1367: self.feedback_integration = PatternFeedbackIntegration()  # â† Sistema promociÃ³n
â”‚
â”œâ”€ Line 2102: Pattern Search ANTES de generar cÃ³digo ğŸ”
â”‚  â””â”€ self.pattern_bank.search_with_fallback()  # â† REUTILIZA patterns
â”‚
â”œâ”€ Line 3026: _phase_8_code_repair() - Learning durante reparaciÃ³n
â”‚  â”œâ”€ 3766: Busca similar_patterns en ErrorPatternStore
â”‚  â”œâ”€ 3898: await error_pattern_store.store_error()  # â† Guarda ERRORES
â”‚  â””â”€ 3972: await error_pattern_store.store_success()  # â† Guarda Ã‰XITOS
â”‚
â””â”€ Line 4739: _phase_11_learning() - Learning post-generaciÃ³n
   â”œâ”€ 4771: feedback_integration.register_successful_generation()  # â† Registra candidato
   â””â”€ 4796: feedback_integration.check_and_promote_ready_patterns()  # â† PROMOCIÃ“N
```

---

## ğŸ”„ Flujo Detallado: De la GeneraciÃ³n al Aprendizaje

### **Fase 1: GeneraciÃ³n de CÃ³digo con Contexto**

**Archivo:** `src/services/code_generation_service.py`

Cuando se genera cÃ³digo nuevo:

```python
# 1. CodeGenerationService intenta generar cÃ³digo
generated_code = await self.llm_client.generate(prompt)

# 2. Se valida el cÃ³digo generado
validation_result = ValidationStrategyFactory.validate(
    code=generated_code,
    file_type=file_type
)

# 3. Si hay errores previos, busca patrones similares
if attempt > 1 and self.pattern_store:
    similar_errors = await self.pattern_store.search_similar_errors(
        task_description=task.description,
        error_message=last_error_msg,
        top_k=3
    )
    # Los errores similares se agregan al prompt como contexto
```

**Detalle clave:** UsÃ¡s **GraphCodeBERT** (768 dimensiones) para generar embeddings semÃ¡nticos del cÃ³digo. Esto permite encontrar patrones similares no solo por texto, sino por estructura de cÃ³digo.

---

### **Fase 2: Registro en Dual Storage (Neo4j + Qdrant)**

**Archivo:** `src/services/error_pattern_store.py`

Cada resultado (error o Ã©xito) se almacena en **DOS bases de datos simultÃ¡neamente**:

#### **Neo4j - Estructura y Queries Complejas**

```cypher
-- Almacena errores con relaciones
CREATE (e:CodeGenerationError {
    error_id: $error_id,
    task_id: $task_id,
    task_description: $task_description,
    error_type: $error_type,
    error_message: $error_message,
    failed_code: $failed_code,
    attempt: $attempt,
    timestamp: datetime($timestamp)
})

-- Almacena Ã©xitos
CREATE (s:SuccessfulCode {
    success_id: $success_id,
    task_id: $task_id,
    task_description: $task_description,
    generated_code: $generated_code,
    quality_score: $quality_score,
    timestamp: datetime($timestamp)
})
```

#### **Qdrant - BÃºsqueda SemÃ¡ntica Vectorial**

```python
# Genera embedding del contexto del error/Ã©xito
error_context = f"""
Task: {error.task_description}
Error Type: {error.error_type}
Error Message: {error.error_message}
Failed Code:
{error.failed_code}
""".strip()

# Usa GraphCodeBERT para embeddings (768-dim)
embedding = self.embedding_model.encode(error_context).tolist()

# Almacena en Qdrant con metadata
point = PointStruct(
    id=str(uuid.uuid4()),
    vector=embedding,  # 768-dimensional vector
    payload={
        "error_id": error.error_id,
        "task_id": error.task_id,
        "task_description": error.task_description,
        "error_type": error.error_type,
        "error_message": error.error_message,
        "failed_code": error.failed_code[:500],
        "attempt": error.attempt,
        "timestamp": error.timestamp.isoformat(),
        "type": "error"
    }
)

self.qdrant.upsert(
    collection_name="code_generation_feedback",
    points=[point]
)
```

**Â¿Por quÃ© dual storage?**
- **Neo4j:** Queries complejas (ej: "errores recurrentes en Ãºltimas 24h por tipo")
- **Qdrant:** BÃºsqueda semÃ¡ntica ultrarrÃ¡pida (encuentra cÃ³digo similar aunque use variables diferentes)

#### **Estructura de Collections en Qdrant**

```
Collection: code_generation_feedback
â”œâ”€ Vectores: 768-dimensional (GraphCodeBERT)
â”œâ”€ Distance: Cosine similarity
â””â”€ Payload: {
    error_id/success_id,
    task_id,
    task_description,
    error_message/generated_code,
    metadata,
    type: "error" | "success"
}

Collection: semantic_patterns (PatternBank)
â”œâ”€ Vectores: 384-dimensional (Sentence-BERT)
â”œâ”€ Distance: Cosine similarity
â””â”€ Payload: {
    pattern_id,
    purpose,
    code,
    success_rate,
    usage_count,
    domain,
    production_ready,
    security_level,
    performance_tier
}
```

---

### **Fase 3: AnÃ¡lisis y Scoring de Patrones**

**Archivo:** `src/cognitive/patterns/pattern_feedback_integration.py`

Cuando un patrÃ³n se registra exitosamente, pasa por mÃºltiples evaluadores:

#### **3.1. QualityEvaluator - MÃ©tricas Objetivas**

```python
class QualityEvaluator:
    def calculate_quality_metrics(self, candidate_id: str) -> QualityMetrics:
        # Success rate (35%)
        success_rate = test_passed / test_total

        # Test coverage (35%)
        test_coverage = coverage_lines_covered / coverage_lines_total

        # Validation score (20%)
        validation_score = rules_passed / rules_total

        # Performance score (10%)
        performance_score = max(0.0, min(1.0, 2.0 - time_ratio))

        # Overall quality (weighted average)
        overall_quality = (
            0.35 * success_rate +
            0.35 * test_coverage +
            0.20 * validation_score +
            0.10 * performance_score
        )

        return QualityMetrics(
            success_rate=success_rate,
            test_coverage=test_coverage,
            validation_score=validation_score,
            performance_score=performance_score,
            overall_quality=overall_quality
        )
```

**Pesos de las mÃ©tricas:**
- **35%** - Success Rate (tests passing)
- **35%** - Test Coverage (code coverage)
- **20%** - Validation Score (validaciones cumplidas)
- **10%** - Performance Score (tiempo de ejecuciÃ³n)

#### **3.2. PatternAnalyzer - AnÃ¡lisis de CÃ³digo**

```python
class PatternAnalyzer:
    def score_reusability(self, code: str) -> float:
        """Analiza reusabilidad del cÃ³digo"""
        score = 1.0

        # Penaliza hardcoded values
        hardcoded_strings = re.findall(r'"[^"]{3,}"', code)
        magic_value_penalty = min(0.3, len(hardcoded_strings) * 0.05)
        score -= magic_value_penalty

        # Bonifica parametrizaciÃ³n
        has_params = bool(re.search(r'def \w+\([^)]+\)', code))
        if has_params:
            score += 0.1

        # Bonifica type hints
        has_type_hints = bool(re.search(r':\s*\w+', code))
        if has_type_hints:
            score += 0.1

        # Bonifica docstrings
        has_docstring = bool(re.search(r'"""[\s\S]*?"""', code))
        if has_docstring:
            score += 0.1

        return max(0.0, min(1.0, score))

    def analyze_security(self, code: str) -> float:
        """Analiza vulnerabilidades de seguridad"""
        score = 1.0

        # Detecta secrets hardcodeados
        secret_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']',
        ]
        for pattern in secret_patterns:
            if re.search(pattern, code, re.IGNORECASE):
                score -= 0.3

        # Detecta SQL injection risks
        if 'execute(' in code and '%s' in code:
            score -= 0.2

        # Detecta eval/exec (peligroso)
        if 'eval(' in code or 'exec(' in code:
            score -= 0.4

        return max(0.0, min(1.0, score))

    def analyze_code_quality(self, code: str) -> float:
        """Analiza calidad del cÃ³digo"""
        score = 1.0

        # Detecta deep nesting (code smell)
        lines = code.split('\n')
        max_indent = 0
        for line in lines:
            if line.strip():
                indent = len(line) - len(line.lstrip())
                max_indent = max(max_indent, indent)

        if max_indent > 16:  # >4 niveles
            score -= 0.2

        # Bonifica error handling
        if 'try:' in code and 'except' in code:
            score += 0.1

        # Bonifica logging
        if 'logger.' in code or 'logging.' in code:
            score += 0.1

        return max(0.0, min(1.0, score))
```

**Criterios de anÃ¡lisis:**

**Reusabilidad:**
- âŒ Penaliza: Hardcoded values, magic numbers
- âœ… Bonifica: ParametrizaciÃ³n, type hints, docstrings

**Seguridad:**
- âŒ Penaliza: Secrets hardcodeados, SQL injection, eval/exec
- âœ… Bonifica: ValidaciÃ³n de inputs, sanitizaciÃ³n

**Calidad de CÃ³digo:**
- âŒ Penaliza: Deep nesting (>4 niveles)
- âœ… Bonifica: Error handling, logging

#### **3.3. DualValidator - ValidaciÃ³n con LLMs**

**Archivo:** `src/cognitive/patterns/dual_validator.py`

Este es el componente mÃ¡s innovador - usa **dos LLMs diferentes** para validar patrones:

```python
class RealDualValidator:
    MIN_SUCCESS_RATE = 0.95      # 95% Ã©xito requerido
    MIN_TEST_COVERAGE = 0.80      # 80% coverage requerido
    MIN_SECURITY_LEVEL = SecurityLevel.MEDIUM
    MIN_COMPLIANCE_LEVEL = ComplianceLevel.PARTIAL
    MIN_PERFORMANCE_SCORE = 0.70
    MIN_QUALITY_SCORE = 0.75

    def validate_pattern(self, pattern: Any, context: Dict[str, Any]) -> ValidationResult:
        """Valida patrÃ³n con mÃ©tricas reales"""

        # 1. Valida success rate
        if success_rate < self.MIN_SUCCESS_RATE:
            issues.append(f"Success rate {success_rate:.2%} below minimum")

        # 2. Valida test coverage
        if test_coverage < self.MIN_TEST_COVERAGE:
            issues.append(f"Test coverage {test_coverage:.2%} below minimum")

        # 3. Analiza seguridad
        security_level = self._analyze_security(code)

        # 4. Analiza performance
        if performance_score < self.MIN_PERFORMANCE_SCORE:
            issues.append(f"Performance score too low")

        # 5. Calcula quality score
        quality_score = self._calculate_quality_score(
            success_rate, test_coverage, security_level,
            performance_score, compliance_level
        )

        # 6. Decide si promover
        should_promote = self._should_promote_internal(
            success_rate, test_coverage, security_level,
            compliance_level, performance_score, quality_score
        )

        return ValidationResult(
            is_valid=len(issues) == 0,
            should_promote=should_promote,
            quality_score=quality_score,
            issues=issues,
            recommendations=recommendations
        )
```

**Thresholds MÃ­nimos:**
- âœ… Success Rate: **â‰¥95%**
- âœ… Test Coverage: **â‰¥80%**
- âœ… Security Level: **â‰¥MEDIUM**
- âœ… Performance Score: **â‰¥0.70**
- âœ… Quality Score: **â‰¥0.75**

---

### **Fase 4: Sistema de PromociÃ³n Multi-Nivel (Stratum)**

**Archivo:** `src/services/pattern_promoter.py`

Tu sistema tiene **3 niveles de confianza** para los patrones:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STRATUM HIERARCHY                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  ğŸ¥‡ TEMPLATE (Highest Trust)                        â”‚
â”‚     â”œâ”€ 99% success rate requerido                   â”‚
â”‚     â”œâ”€ 50+ runs exitosos                            â”‚
â”‚     â”œâ”€ 0 regresiones                                â”‚
â”‚     â”œâ”€ 14 dÃ­as de estabilidad                       â”‚
â”‚     â”œâ”€ 5+ proyectos distintos                       â”‚
â”‚     â””â”€ ğŸ”’ Requiere revisiÃ³n humana                  â”‚
â”‚                                                      â”‚
â”‚  ğŸ¥ˆ AST (Medium Trust)                              â”‚
â”‚     â”œâ”€ 95% success rate requerido                   â”‚
â”‚     â”œâ”€ 10+ runs exitosos                            â”‚
â”‚     â”œâ”€ 0 regresiones                                â”‚
â”‚     â”œâ”€ 3 dÃ­as de estabilidad                        â”‚
â”‚     â”œâ”€ 3+ proyectos distintos                       â”‚
â”‚     â””â”€ âœ… PromociÃ³n automÃ¡tica                      â”‚
â”‚                                                      â”‚
â”‚  ğŸ¥‰ LLM (Lowest Trust - Starting Point)             â”‚
â”‚     â”œâ”€ CÃ³digo reciÃ©n generado                       â”‚
â”‚     â”œâ”€ Sin historial probado                        â”‚
â”‚     â””â”€ Requiere validaciÃ³n                          â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Criterios Formales de PromociÃ³n (Phase 7)**

```python
PROMOTION_CRITERIA_FORMAL = {
    "llm_to_ast": FormalPromotionCriteria(
        min_distinct_projects=3,
        min_semantic_compliance=1.00,       # 100% compliance!
        max_regressions_golden_apps=0,
        min_successful_runs=10,
        max_generation_time_variance=0.50,  # 50% variance OK
        requires_no_project_context=False,
    ),
    "ast_to_template": FormalPromotionCriteria(
        min_distinct_projects=5,
        min_semantic_compliance=1.00,       # Perfect compliance
        max_regressions_golden_apps=0,
        min_successful_runs=50,
        max_generation_time_variance=0.10,  # Solo 10% variance
        requires_no_project_context=True,   # Debe ser context-free
    ),
}
```

**ComparaciÃ³n de Criterios:**

| Criterio | LLM â†’ AST | AST â†’ TEMPLATE |
|----------|-----------|----------------|
| Success Rate | â‰¥95% | â‰¥99% |
| Successful Runs | â‰¥10 | â‰¥50 |
| Distinct Projects | â‰¥3 | â‰¥5 |
| Regressions | 0 | 0 |
| Semantic Compliance | 100% | 100% |
| Time Variance | <50% | <10% |
| Context-Free | No | **SÃ­** |
| Human Review | No | **SÃ­** |

#### **Proceso de EvaluaciÃ³n**

```python
async def _attempt_auto_promotion(
    self,
    candidate: PatternCandidate,
    quality_metrics: QualityMetrics
) -> bool:
    # 1. Analiza el patrÃ³n
    reusability = self.pattern_analyzer.score_reusability(candidate.code)
    security = self.pattern_analyzer.analyze_security(candidate.code)
    code_quality = self.pattern_analyzer.analyze_code_quality(candidate.code)

    # 2. Calcula promotion score
    promotion_score = (
        0.4 * quality_metrics.overall_quality +
        0.3 * reusability +
        0.2 * security +
        0.1 * code_quality
    )

    # 3. Verifica threshold adaptativo por dominio
    threshold = self.quality_evaluator.get_threshold(candidate.domain)
    adjusted_threshold = self.threshold_manager.get_adjusted_threshold(
        candidate.domain,
        threshold.promotion_score
    )

    if promotion_score < adjusted_threshold:
        return False  # No promover

    # 4. Dual-validator (Claude + GPT-4)
    validation_result = self.dual_validator.validate_pattern(
        pattern=candidate,
        context={
            'quality_metrics': quality_metrics,
            'code': candidate.code,
            'signature': candidate.signature
        }
    )

    if not validation_result.should_promote:
        return False

    # 5. PROMOCIÃ“N EXITOSA
    logger.info(f"ğŸš€ Pattern {candidate.candidate_id} PROMOTED!")
    candidate.status = PromotionStatus.PROMOTED

    # Track en sistema adaptativo
    self.threshold_manager.track_promotion(candidate.domain, success=True)

    return True
```

**FÃ³rmula de Promotion Score:**
```
promotion_score =
    0.4 Ã— overall_quality +     (Quality metrics weighted)
    0.3 Ã— reusability +         (Code reusability)
    0.2 Ã— security +            (Security analysis)
    0.1 Ã— code_quality          (Code quality)
```

#### **Sistema de Demotion (Agresivo)**

**FilosofÃ­a:** Conservative promotion, **AGGRESSIVE demotion**

```python
DEMOTION_THRESHOLDS = {
    "failure_rate": 0.10,     # >10% failures â†’ demote
    "regression_count": 1,    # ANY regression â†’ demote
    "recent_failures": 3,     # 3 failures in last 10 runs â†’ demote
}

def evaluate_demotion(
    self,
    pattern_id: str,
    metrics: PatternMetrics,
    recent_results: List[bool]
) -> Optional[Stratum]:
    """Conservative promotion, AGGRESSIVE demotion"""

    # Check 1: Overall failure rate
    failure_rate = metrics.failed_runs / metrics.total_runs
    if failure_rate > 0.10:
        return self._get_previous_stratum(current)

    # Check 2: ANY regression triggers demotion
    if metrics.regression_count >= 1:
        return self._get_previous_stratum(current)

    # Check 3: Recent failures (last 10 runs)
    recent_failures = sum(1 for r in recent_results[-10:] if not r)
    if recent_failures >= 3:
        return self._get_previous_stratum(current)

    return None  # No demotion needed
```

**Triggers de Demotion:**
- âŒ Failure rate **>10%**
- âŒ **ANY** regression detectada
- âŒ **3+ failures** en Ãºltimos 10 runs

---

### **Fase 5: Almacenamiento en PatternBank y ReutilizaciÃ³n**

**Archivo:** `src/cognitive/patterns/pattern_bank.py`

Una vez que un patrÃ³n es **PROMOTED**, se almacena en el **PatternBank** con embeddings duales:

#### **Dual Embeddings (GraphCodeBERT + Sentence-BERT)**

```python
def store_pattern(
    self,
    signature: SemanticTaskSignature,
    code: str,
    success_rate: float
) -> str:
    # 1. Valida threshold (â‰¥95% success rate)
    if success_rate < 0.95:
        raise ValueError("success_rate must be â‰¥ 0.95")

    # 2. Genera dual embeddings
    if self.enable_dual_embeddings:
        pattern_dict = {
            'code': code,
            'description': signature.purpose,
            'pattern_id': pattern_id
        }
        dual_emb = self.dual_generator.generate_batch([pattern_dict])[0]

        code_embedding = dual_emb.code_embedding      # GraphCodeBERT 768-dim
        semantic_embedding = dual_emb.semantic_embedding  # Sentence-BERT 384-dim

    # 3. Almacena en AMBAS colecciones de Qdrant
    # - devmatrix_patterns (code embeddings)
    # - semantic_patterns (semantic embeddings)

    # 4. Metadata enriquecida
    metadata = {
        "pattern_id": pattern_id,
        "purpose": signature.purpose,
        "domain": signature.domain,
        "category": classification_result.category,
        "code": code,
        "success_rate": success_rate,
        "usage_count": 0,
        "created_at": datetime.utcnow().isoformat(),

        # Production readiness (Task Group 8)
        "production_ready": False,
        "production_readiness_score": production_score,
        "test_coverage": 0.0,
        "security_level": security_level,
        "performance_tier": performance_tier,
    }

    return pattern_id
```

**Dual Embeddings Explicados:**

| Embedding | Modelo | Dimensiones | PropÃ³sito |
|-----------|--------|-------------|-----------|
| Code | GraphCodeBERT | 768 | Captura estructura sintÃ¡ctica del cÃ³digo |
| Semantic | Sentence-BERT | 384 | Captura significado semÃ¡ntico del propÃ³sito |

#### **BÃºsqueda Inteligente con Fallback**

```python
def search_with_fallback(
    self,
    signature: SemanticTaskSignature,
    top_k: int = 5,
    min_results: int = 3,
) -> List[StoredPattern]:
    """TG4: Adaptive thresholds + TG5: Keyword fallback"""

    # 1. Threshold adaptativo por dominio
    domain_thresholds = {
        "crud": 0.60,
        "custom": 0.65,
        "payment": 0.70,
        "workflow": 0.65,
    }
    adaptive_threshold = domain_thresholds.get(
        signature.domain.lower(), 0.60
    )

    # 2. BÃºsqueda semÃ¡ntica
    semantic_results = self.search_patterns(
        signature,
        top_k=top_k,
        similarity_threshold=adaptive_threshold,
    )

    # 3. Si hay suficientes resultados, devolver
    if len(semantic_results) >= min_results:
        return semantic_results

    # 4. TG5: Keyword Fallback
    logger.info("ğŸ”„ TG5: Triggering keyword fallback")

    # Extrae keywords
    keywords = self._extract_keywords(signature.purpose)

    # Mapea a pattern types
    keyword_patterns = set()
    for keyword in keywords:
        pattern_type = self._keyword_to_pattern_type(keyword)
        if pattern_type:
            keyword_patterns.add(pattern_type)

    # BÃºsqueda mÃ¡s amplia con threshold bajo
    broad_results = self.search_patterns(
        signature,
        top_k=top_k * 2,
        similarity_threshold=0.4,  # Very low
    )

    # Filtra por keyword match
    keyword_results = [
        pattern for pattern in broad_results
        if self._matches_keywords(pattern, keyword_patterns)
    ]

    # 5. Combina y deduplica
    combined = self._deduplicate(semantic_results + keyword_results)

    # 6. Ordena por similarity y limita a top_k
    combined.sort(key=lambda p: p.similarity_score, reverse=True)
    return combined[:top_k]
```

**Thresholds Adaptativos por Dominio:**

| Dominio | Threshold | RazÃ³n |
|---------|-----------|-------|
| CRUD | 0.60 | Operaciones estÃ¡ndar, mÃ¡s variaciones vÃ¡lidas |
| Custom | 0.65 | LÃ³gica especÃ­fica, mayor precisiÃ³n requerida |
| Payment | 0.70 | CrÃ­tico, requiere exactitud mÃ¡xima |
| Workflow | 0.65 | LÃ³gica de negocio, precisiÃ³n moderada |

**Keyword Fallback (TG5):**

Cuando la bÃºsqueda semÃ¡ntica no encuentra suficientes resultados (< `min_results`):

1. **Extrae keywords** del `signature.purpose`
2. **Mapea keywords â†’ pattern types** (ej: "create" â†’ "crud", "auth" â†’ "auth")
3. **BÃºsqueda amplia** con threshold muy bajo (0.4)
4. **Filtra** por keyword matches
5. **Combina** con resultados semÃ¡nticos
6. **Ordena** por similarity score

---

## ğŸ”„ Ciclo Completo de PromociÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PATTERN PROMOTION PIPELINE (Milestone 4)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£  CODE GENERATION
    â”œâ”€ LLM genera cÃ³digo
    â”œâ”€ Se ejecutan tests
    â””â”€ Se valida sintaxis/semÃ¡ntica

2ï¸âƒ£  REGISTRATION
    â”œâ”€ PatternFeedbackIntegration.register_successful_generation()
    â”œâ”€ QualityEvaluator.store_candidate()
    â””â”€ Metadata: test_results, validation_results

3ï¸âƒ£  EXECUTION TRACKING
    â”œâ”€ QualityEvaluator.track_execution_results()
    â”‚   â””â”€ Tests passed/total, coverage, execution time
    â””â”€ QualityEvaluator.track_validation_results()
        â””â”€ Rules passed/total, type hints coverage

4ï¸âƒ£  QUALITY CALCULATION
    â”œâ”€ QualityEvaluator.calculate_quality_metrics()
    â”‚   â”œâ”€ success_rate (35%)
    â”‚   â”œâ”€ test_coverage (35%)
    â”‚   â”œâ”€ validation_score (20%)
    â”‚   â””â”€ performance_score (10%)
    â””â”€ Overall quality = weighted average

5ï¸âƒ£  PATTERN ANALYSIS
    â”œâ”€ PatternAnalyzer.score_reusability()
    â”‚   â””â”€ Checks: hardcoded values, params, type hints, docs
    â”œâ”€ PatternAnalyzer.analyze_security()
    â”‚   â””â”€ Checks: secrets, SQL injection, eval/exec
    â””â”€ PatternAnalyzer.analyze_code_quality()
        â””â”€ Checks: nesting, error handling, logging

6ï¸âƒ£  PROMOTION SCORING
    â”œâ”€ Calculate composite score:
    â”‚   promotion_score = 0.4*quality + 0.3*reusability +
    â”‚                     0.2*security + 0.1*code_quality
    â”œâ”€ Get domain threshold (adaptive)
    â””â”€ Compare: promotion_score >= adjusted_threshold

7ï¸âƒ£  DUAL VALIDATION
    â”œâ”€ RealDualValidator.validate_pattern()
    â”‚   â”œâ”€ Success rate â‰¥ 95%?
    â”‚   â”œâ”€ Test coverage â‰¥ 80%?
    â”‚   â”œâ”€ Security level â‰¥ MEDIUM?
    â”‚   â”œâ”€ Performance score â‰¥ 0.70?
    â”‚   â””â”€ Quality score â‰¥ 0.75?
    â””â”€ should_promote = all criteria met

8ï¸âƒ£  PROMOTION/REJECTION
    â”œâ”€ If approved:
    â”‚   â”œâ”€ candidate.status = PromotionStatus.PROMOTED
    â”‚   â”œâ”€ Store in PatternBank with embeddings
    â”‚   â”œâ”€ Track usage count
    â”‚   â””â”€ Update ranking_score in Neo4j DAG
    â””â”€ If rejected:
        â”œâ”€ candidate.status = PromotionStatus.REJECTED
        â”œâ”€ Log blocking issues
        â””â”€ Track for learning (adjust thresholds)

9ï¸âƒ£  REUSE
    â”œâ”€ Future generations search PatternBank
    â”œâ”€ Semantic similarity + keyword fallback
    â”œâ”€ DAG-based ranking boost
    â””â”€ Increment usage_count on retrieval
```

---

## ğŸ’» Uso en el Pipeline E2E

### **Phase 1: InicializaciÃ³n de Servicios**

**Archivo:** `tests/e2e/real_e2e_full_pipeline.py:1254`

```python
async def _initialize_services(self):
    """Initialize real cognitive services with minimal output"""

    # 1. PatternBank - almacena patterns promovidos
    self.pattern_bank = PatternBank()
    self.pattern_bank.connect()

    # 2. ErrorPatternStore - guarda errores/Ã©xitos
    self.error_pattern_store = ErrorPatternStore()

    # 3. PatternFeedbackIntegration - orquestador
    self.feedback_integration = PatternFeedbackIntegration(
        enable_auto_promotion=False,  # Manual control for testing
        mock_dual_validator=True       # Use mock for testing
    )
```

### **Phase 2: BÃºsqueda de Patterns Durante GeneraciÃ³n**

**Archivo:** `tests/e2e/real_e2e_full_pipeline.py:2097`

```python
# Para cada requirement, buscar patterns existentes
for req in self.requirements:
    signature = SemanticTaskSignature(
        purpose=req.description,
        inputs={"request": "dict"},
        outputs={"code": "str"},
        domain="api_development"
    )

    # TG4 (adaptive thresholds) + TG5 (keyword fallback)
    results = self.pattern_bank.search_with_fallback(
        signature=signature,
        top_k=10,
        min_results=3  # Trigger keyword fallback if < 3 results
    )

    if results:
        logger.info(f"ğŸ” Found {len(results)} matching patterns")
        self.patterns_matched.extend(results)
```

### **Phase 8: Learning Durante Code Repair**

**Archivo:** `tests/e2e/real_e2e_full_pipeline.py:3026`

```python
async def _phase_8_code_repair(self):
    """Code Repair con learning activo"""

    # Repair loop
    for iteration in range(max_iterations):
        # Step 2: Buscar patterns similares
        if self.error_pattern_store:
            similar_patterns = await self.error_pattern_store.search_similar_errors(
                task_description=f"Phase 6.5 Code Repair - {self.spec_name}",
                error_message=compliance_failures,
                top_k=3
            )
            pattern_reuse_count += len(similar_patterns)

        # Step 3-6: Aplicar repairs y validar
        repair_result = await self.code_repair_agent.repair(...)
        new_compliance_report = self.compliance_validator.validate_from_app(...)

        # Step 7: Detectar regresiÃ³n
        if new_compliance < current_compliance:
            # Store failed repair pattern
            await self.error_pattern_store.store_error(
                ErrorPattern(
                    error_id=str(uuid4()),
                    task_description=f"Phase 6.5 Code Repair - {self.spec_name}",
                    error_type="regression",
                    error_message=f"Regression: {current:.1%} â†’ {new:.1%}",
                    failed_code=str(repair_result)[:500],
                    attempt=iteration,
                    metadata={
                        "compliance_before": current_compliance,
                        "compliance_after": new_compliance,
                        "regression": True
                    }
                )
            )
        else:
            # Step 8: Store successful repair pattern
            await self.error_pattern_store.store_success(
                SuccessPattern(
                    success_id=str(uuid4()),
                    task_description=f"Phase 6.5 Code Repair - {self.spec_name}",
                    generated_code=str(repair_result)[:1000],
                    quality_score=new_compliance,
                    metadata={
                        "compliance_after": new_compliance,
                        "tests_fixed": tests_fixed,
                        "spec_name": self.spec_name
                    }
                )
            )
```

### **Phase 11: Learning Post-GeneraciÃ³n**

**Archivo:** `tests/e2e/real_e2e_full_pipeline.py:4739`

```python
async def _phase_11_learning(self):
    """Phase 10: Learning - Store successful patterns for future reuse"""

    if not self.feedback_integration:
        logger.warning("PatternFeedbackIntegration not available")
        return

    # Register successful code generation
    if self.execution_successful:
        # Combine all generated Python code
        combined_code = "\n\n".join([
            f"# File: {filename}\n{content}"
            for filename, content in self.generated_code.items()
            if filename.endswith('.py')
        ])

        # Create execution result
        execution_result = self._create_execution_result()

        # Register with feedback system
        candidate_id = await self.feedback_integration.register_successful_generation(
            code=combined_code,
            signature=self.task_signature,
            execution_result=execution_result,
            task_id=uuid4(),
            metadata={
                "spec_name": self.spec_name,
                "patterns_matched": len(self.patterns_matched),
                "duration_ms": self.metrics_collector.metrics.total_duration_ms,
                "files_generated": len(self.generated_code),
                "requirements_count": len(self.requirements)
            }
        )

        logger.info(f"âœ… Pattern candidate registered: {candidate_id}")

    # Check for patterns ready for promotion
    promotion_stats = self.feedback_integration.check_and_promote_ready_patterns()

    logger.info(f"ğŸ“Š Promotion Results:")
    logger.info(f"  - Total candidates: {promotion_stats.get('total_candidates', 0)}")
    logger.info(f"  - Promoted: {promotion_stats.get('promotions_succeeded', 0)}")
    logger.info(f"  - Failed: {promotion_stats.get('promotions_failed', 0)}")

    # Update metrics
    self.metrics_collector.metrics.patterns_stored = 1 if self.execution_successful else 0
    self.metrics_collector.metrics.patterns_promoted = promotion_stats.get("promotions_succeeded", 0)
    self.metrics_collector.metrics.candidates_created = 1 if self.execution_successful else 0
```

---

## ğŸ“ˆ MÃ©tricas del Sistema de Learning

**Archivo:** `src/services/error_pattern_analyzer.py`

El sistema mide su propia efectividad:

```python
async def calculate_learning_effectiveness(
    self,
    time_window_hours: int = 24
) -> LearningMetrics:
    # 1. Total errors en ventana de tiempo
    total_errors = neo4j_query("MATCH (e:CodeGenerationError) WHERE ...")

    # 2. Errors donde se usÃ³ feedback (attempt > 1)
    errors_with_feedback = neo4j_query("... WHERE e.attempt > 1")

    # 3. Success rates con/sin feedback
    with_feedback_stats = neo4j_query("... WHERE used_feedback = true")
    without_feedback_stats = neo4j_query("... WHERE used_feedback = false")

    success_rate_with = with_fb_successes / with_fb_total
    success_rate_without = without_fb_successes / without_fb_total

    # 4. Improvement percentage
    improvement = (
        (success_rate_with - success_rate_without) /
        success_rate_without * 100
    )

    return LearningMetrics(
        total_errors=total_errors,
        errors_with_feedback=errors_with_feedback,
        success_rate_without_feedback=success_rate_without,
        success_rate_with_feedback=success_rate_with,
        improvement_percentage=improvement,
        avg_retries_with_feedback=avg_retries_with,
        avg_retries_without_feedback=avg_retries_without,
    )
```

**MÃ©tricas Clave:**

| MÃ©trica | DescripciÃ³n | Objetivo |
|---------|-------------|----------|
| `total_errors` | Total de errores en ventana de tiempo | Monitor general |
| `errors_with_feedback` | Errores que usaron feedback | Uso del sistema |
| `success_rate_without_feedback` | Success rate sin learning | Baseline |
| `success_rate_with_feedback` | Success rate con learning | Efectividad |
| `improvement_percentage` | % mejora con learning | **KPI Principal** |
| `avg_retries_with_feedback` | Promedio de reintentos con feedback | Eficiencia |
| `avg_retries_without_feedback` | Promedio de reintentos sin feedback | ComparaciÃ³n |

---

## ğŸ¯ Puntos Clave del Sistema de Learning

### **1. Captura de Patrones Exitosos**

âœ… **Threshold estricto:** Solo patrones con â‰¥95% success rate
âœ… **ValidaciÃ³n mÃºltiple:** Tests + validations + mÃ©tricas de calidad
âœ… **Embeddings code-aware:** GraphCodeBERT entiende sintaxis y semÃ¡ntica
âœ… **Metadata rica:** Domain, security level, performance tier, usage count

### **2. Almacenamiento Dual (Neo4j + Qdrant)**

```
Neo4j (Relacional):
â”œâ”€ Queries complejas
â”œâ”€ AnÃ¡lisis de tendencias
â”œâ”€ DetecciÃ³n de errores recurrentes
â””â”€ DAG de dependencias

Qdrant (Vectorial):
â”œâ”€ BÃºsqueda semÃ¡ntica ultrarrÃ¡pida
â”œâ”€ Cosine similarity
â”œâ”€ GraphCodeBERT embeddings (768D)
â””â”€ Sentence-BERT embeddings (384D)
```

### **3. Sistema de PromociÃ³n Multi-Nivel**

```python
# FilosofÃ­a: Conservative promotion, aggressive demotion

Promotion Requirements (LLM â†’ AST):
âœ… 95% success rate
âœ… 10+ successful runs
âœ… 0 regressions
âœ… 3 days stability
âœ… 3+ distinct projects
âœ… 100% semantic compliance
âœ… <50% generation time variance

Promotion Requirements (AST â†’ TEMPLATE):
âœ… 99% success rate
âœ… 50+ successful runs
âœ… 0 regressions
âœ… 14 days stability
âœ… 5+ distinct projects
âœ… 100% semantic compliance
âœ… <10% generation time variance
âœ… Context-independent (no project-specific code)
âœ… ğŸ”’ Human review required

Demotion Triggers (INSTANT):
âŒ >10% failure rate
âŒ ANY regression detected
âŒ 3+ failures in last 10 runs
```

### **4. ReutilizaciÃ³n Inteligente**

#### **BÃºsqueda SemÃ¡ntica:**
```python
query_text = "Create a new user"
query_embedding = encode(query_text)  # 768-dim vector

# Busca en Qdrant con cosine similarity
results = qdrant.search(
    collection_name="semantic_patterns",
    query_vector=query_embedding,
    score_threshold=0.60,  # Adaptive per domain
    limit=5
)
```

#### **Ranking con DAG (Milestone 3):**
```python
def _get_dag_ranking_score(pattern_id: str) -> float:
    # Formula:
    # Base: Pattern's Neo4j ranking_score (0.0-1.0)
    # Boost: Recent successes (+0.10 if within 7 days)
    # Penalty: Failed executions (-0.05 per failure)
    # Efficiency: Fast + low memory (+0.03 if <5s and <256MB)

    base_score = neo4j_query(pattern_id).ranking_score

    if has_recent_successes(pattern_id):
        base_score += 0.10

    failures = count_recent_failures(pattern_id)
    base_score -= 0.05 * failures

    if is_resource_efficient(pattern_id):
        base_score += 0.03

    return clamp(base_score, 0.0, 1.0)
```

---

## ğŸ“ Conclusiones Clave

Tu sistema de learning es **production-grade machine learning** integrado directamente en el pipeline de cÃ³digo. Las caracterÃ­sticas mÃ¡s destacadas son:

### **1. Dual Storage Strategy**
- **Neo4j** para relaciones y queries complejas
- **Qdrant** para bÃºsqueda semÃ¡ntica ultrarrÃ¡pida

### **2. Multi-Level Trust System (Stratum)**
- **PromociÃ³n conservadora** (earn trust slowly)
- **Demotion agresiva** (lose trust quickly)
- **Thresholds adaptativos** por dominio

### **3. Comprehensive Quality Scoring**
- Quality metrics (tests + coverage + validation)
- Pattern analysis (reusability + security + code quality)
- Dual LLM validation (Claude + GPT-4)
- Composite promotion score (weighted formula)

### **4. Intelligent Retrieval**
- Semantic search con GraphCodeBERT embeddings
- Adaptive thresholds por dominio
- Keyword fallback cuando no hay matches semÃ¡nticos
- DAG-based ranking (execution success boosts ranking)

### **5. Self-Measuring System**
- Learning effectiveness metrics
- Recurring error detection
- Problematic task identification
- Improvement recommendations

**El flujo completo:**
```
Code Generation â†’ Validation â†’ Registration â†’ Analysis â†’ Scoring â†’
Dual Validation â†’ Promotion/Demotion â†’ PatternBank Storage â†’
Reuse in Future Generations â†’ Feedback Loop Closes
```

Es un sistema que literalmente **aprende de sus errores y Ã©xitos**, mejorando continuamente la calidad del cÃ³digo generado. ğŸš€

---

## ğŸ“š Referencias

### Archivos Principales del Sistema

```
Core Learning Components:
â”œâ”€ src/cognitive/patterns/pattern_feedback_integration.py
â”œâ”€ src/cognitive/patterns/pattern_bank.py
â”œâ”€ src/cognitive/patterns/pattern_analyzer.py
â”œâ”€ src/cognitive/patterns/dual_validator.py
â”œâ”€ src/services/error_pattern_store.py
â”œâ”€ src/services/pattern_promoter.py
â””â”€ tests/e2e/real_e2e_full_pipeline.py

Supporting Services:
â”œâ”€ src/services/code_generation_service.py
â”œâ”€ src/services/error_pattern_analyzer.py
â””â”€ src/cognitive/planning/multi_pass_planner.py
```

### TecnologÃ­as Clave

- **GraphCodeBERT:** 768-dimensional code embeddings
- **Sentence-BERT:** 384-dimensional semantic embeddings
- **Qdrant:** Vector database para bÃºsqueda semÃ¡ntica
- **Neo4j:** Graph database para relaciones y DAG
- **Claude + GPT-4:** Dual LLM validation

---

**Ãšltima actualizaciÃ³n:** 2025-11-28
**Estado:** ProducciÃ³n - Sistema activo en E2E pipeline
